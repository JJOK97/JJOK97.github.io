{"a_project/a_review/moremore-review-1":{"slug":"a_project/a_review/moremore-review-1","filePath":"a_project/a_review/moremore-review-1.md","title":"모아모아 리뷰하기","links":[],"tags":["Dev","Portfolio","Frontend","Fintech","Project","Review"],"content":"오늘은 이전에 진행했던 프로젝트의 커밋내역을 통해서 포트폴리오를 한번 정리해 보려 합니다.\n최애 프로젝트를 한번 열어봤는데 만들고 수정한 기능만 140개가 되네요..\n아래와 같은 것들이 코드리뷰를 기다리고 있었습니다.\n\n\n막상 코드를 열어보니 대부분 화면 구성하는데 시간을 다 써서 이력서에 자랑할만한 내용은 별로 없는거같아요. 여태 화면 구현하고 동작시키는게 재미있어서 프론트 포지션을 자처했는데, 조금 더 기술이나 서비스에 대해서 목표지향적으로 움직였으면 더 좋지않았나 하는 생각이듭니다.\n못해도 보안 수준을 더 높인다던가, 데이터 파싱을 효율적으로 한다거나, 라이브러리의 세부적인 기능까지 아주 퍼펙트하게 사용을 한다.. 이런 부분들이 포트폴리오를 작성할 때 강점이 될꺼같고, 그 다음으로 컴포넌트나 훅을 기가 막히게 구축하고 활용한다. 프론트 개발속도가 아주 빠르다.. ( 하루에 2~3페이지씩 뚝딱 만드는사람도 보았습니다.. ) 이런 정도는 되어야 강점으로서 내세울수있지 않을까 하네요.\n제 코드에 대해서 커밋리뷰는 처음 해보는건데 생각보다 얻어가는게 많은거같아요.\n위와같이 부족한점도 금방 찾아내고, 또 말로만 컨벤션을 좋아한다면서 태그에 대소문자 구별도 안하는 제 모습을 보면서 웃기기도하네요.\r\n앞으로는 더 주의하면서 프로젝트에 참여하도록 노력해야겠습니다.\n아무튼 이러한 코드리뷰를 지금 부터 한 3~4시간은 더 해야할듯한데, 과거의 진석이가 제발 참신한 개발을 했길 바랍니다.\n좋은 포트폴리오 나오면 공유를 하도록 하겠습니다..!"},"a_project/a_review/zoom-defense-review":{"slug":"a_project/a_review/zoom-defense-review","filePath":"a_project/a_review/zoom-defense-review.md","title":"Zoom Defense 회고","links":[],"tags":["Dev","Portfolio","Frontend","Backend","Project","Review"],"content":"우리에게 주어진 시간은..\n3월 19일, 20일 그리고 21일 오전 4시간 가량….\r\n진짜 우리팀은 이 마지막 4시간까지도 단 1분도 허투루 사용하지 않았다고 자부할 수 있다.\r\n우리는 발표 준비와, 명세서, 디버깅을 할 시간이 필요했는데,\r\n그 짧은 이틀간 통하는게 생긴건지… 네 사람이 일체가 되어 각각의 작업들을 동시에 처리해 나가기 시작했다.\n팀장으로서 굳이 신경쓰지 않아도, 스스로가 맡은일을 완벽에 가깝에 수행을 하였기에\r\n나 또한 정말 오랫만에 팀원들을 신뢰하며 문제들을 쳐 내 나갔으며.. 그렇게 오전중에 열댓개나 되는 버그를 처리하여 메인에 넣을 수 있었다.\n과연 어떤점이 이렇게 한 팀으로 묶을 수 있었을까?\r\n좋은 사람들끼리 뭉친건가.. 아니면 눈에 보이지 않는 영향력이 있었던건가 참 궁금해지는 프로젝트였다.\n\n그렇게 오전 중으로 모든 준비를 마친 우리는..\n힘들었던 작업들을 회상하며 발표 순서를 기다렸다.\n사실 한가지 빼먹은게 있었는데, 내가 발표자로서 발표준비를 하지 못했다는 것.\r\n근데 3일의 프로젝트기간에 어느 누가 발표준비를 완벽하게 해오겟는가..\r\n생각하며 나 또한 맘 편히 PPT 순서를 정리하고 있었다.\n근데 웬걸… 우리 앞조의 평가가 꽤나 야박하다..\r\nPPT의 세부적인 흐름이나 제한시간을 따지는 등\r\n옛날 잔인했던 SSAFY 생각이 떠오르기도 했고.. ( 상상도 하기 싫다… )\r\n그러면서 심박수가 점점 올라가며 머리가 살짝 하얘지기 시작했다.\n흐름도 아주 단순하고 명확하게 구분을 해뒀으나 그 흐름조차 생각이 나지않더라..\n그렇게 잡은 마이크..\r\n초장에는 꽤나 호기롭게 잘 헤쳐나갔다..\r\n참신한 기획배경에 다들 흥미로워하는 분위기였다.\n그러나 기술 설명으로 들어가는 순간\r\nPPT 클리커를 한 번 잘못누르면서 PPT가 살짝 꼬이게되었고, 내 머릿속도 꼬이게 되었고, 당연히 뒷 페이지가 뭔지 기억안나더라..\r\n시간은 이미 굉장히 많이 흐른 것 같고, 얼른 정리하자는 마음으로 우리의 성공 스토리를 반정도는 접어서 날려보내버리며 중반부가 지나갔다.\n마지막으로 들어서도 게임 시연을 할 때, 어떻게 시연을 할 지 구체적으로 연습을 하지 않았더니\r\n손발이 살짝 맞지않았는데, 나중에 얘길 들어보니 그때 귀가 여태 본것중에 가장 빨갰다고 하더라 ㅋㅋㅋ\n\n그렇게 마무리 된 발표..\n우리 팀이 꽤나 공격적으로 기술들을 활용을 했기에 기술적인 부분으로나, 개발자 태도와 같은 부분에서 평이 좋았던걸로 기억한다.\r\n내 스스로의 목표였던 인재 개발원에서 한번도 보지못했던 미니프로젝트를 성공한거같아서 어느 프로젝트를 끝냈을때보다도 성취감이 좋았다.\n그러나 역시 예상한대로 PPT를 너무 스킵해서 그 부분이 많이 아쉬웠다고 한다.\r\n진짜 나는 발표준비를 하지 못해 뒷 페이지를 넘길때마다… 엇 얘가 나오면 안되는데.. 하면서 넘긴건데\r\n다행히 재영선생님께서 시간이 부족해서 넘긴거라 판단된다라고 너무나도 멋지게 포장해주셨다.\n이렇게 발표가 마무리 되고 나니\r\n참 발표력에 대해서 너무 아쉽다고 생각이 많이 들기도 하고,\r\n나는 발표 준비를 하는데 시간이 굉장히 많이 드는 사람인데 앞으로 팀장으로서 팀 운영과 동시에 발표를 해야 한다면..\r\n어떻게 발표 시간을 할애를 해야 할 지 고민이 되었다.\n보통은 하루 몇 시간 보면 어느정도 발표를 기똥차게 준비를 해오던데,\r\n나는 대본을 준비한다면 일주일이 넘게 암기를 하는 시간이 필요한거같다.\n대본이 없다면 오히려 겁없는 하룻강아지처럼 발표를 할 수 있으나, 그 날의 입이 터지는거에 따라서 너무 퀄리티가 달라진다.\n방금 한 5분간 고민을 해봤는데, 왕도가 있겠는가.. 라는 결론이 났다.\r\n사실 프로젝트 마무리하면서 이제 팀장의 자리는 다른사람에게도 기회를 넘기려고 하였으나,\r\n나는 아직 여전히 미생이다.\r\n남은 프로젝트도 직접 발표를 하며, 경험을 통해 성장하는 내가 되어야겠다고 다짐을 했다.\n화이팅\n\n\n  \n     프로젝트 GitHub\n  \n  \n     프로젝트 노션\n  \n  \n     버그 상황판\n  \n"},"a_project/git/git-guide-1":{"slug":"a_project/git/git-guide-1","filePath":"a_project/git/git-guide-1.md","title":"개념과 Git Tools","links":[],"tags":["Dev","Git","GitHub","Collaboration"],"content":"👉 이전 편: 노션 협업 템플릿\n\n신입 개발자로 첫 프로젝트에 참여할 때 가장 먼저 마주하는 과제 중 하나는 협업입니다.\n개인 프로젝트에서는 단순히 Ctrl + S를 눌러 파일을 저장하면 되었지만,\n협업에서는 여러 사람이 동시에 같은 코드를 수정하고 관리해야 합니다.\n이때 필수적으로 익혀야 할 것이 바로 Git과 Git Tool입니다.\n이 글에서는 협업을 시작하는 신입 개발자가 반드시 알아야 할\nGit의 개념과 Git을 쉽게 사용하도록 도와주는 도구들의 활용법 정리했습니다.\n\n💡 Git이 중요한 이유\nGit은 버전 관리 시스템으로, 코드의 변경 이력을 저장하고 되돌릴 수 있는 기능을 제공합니다.\n단순히 파일을 복사하여 백업하는 방식도 가능하지만, 협업 환경에서는 이러한 방법에 한계가 있습니다.\n\nGit을 사용하면 다음과 같은 장점이 있습니다.\n✅ 코드 히스토리를 추적할 수 있습니다 → 누가 언제 어떤 코드를 수정했는지 확인 가능\n✅ 다른 개발자와 충돌 없이 협업할 수 있습니다 → 여러 사람이 동시에 같은 파일을 수정해도 문제 해결 가능\n✅ 코드를 안전하게 되돌릴 수 있습니다 → 실수해도 이전 상태로 복구 가능\n✅ 브랜치를 활용해 기능 개발을 병렬로 진행할 수 있습니다 → 개발 속도 향상\n\n이처럼 Git은 협업에서 필수적인 도구입니다. 하지만 Git만 익힌다고 협업이 완벽해지는 것은 아닙니다.\n더 효율적인 협업을 위해 함께 활용할 수 있는 도구들이 있습니다.\n\n💡 Git과 함께 사용하면 좋은 도구들\nGit을 보다 편리하게 사용하기 위해 다양한 도구들이 존재합니다.\n다음은 신입 개발자가 알아두면 좋은 대표적인 Git 관련 도구들입니다.\n1. 코드 저장소 플랫폼\nGit만으로 버전 관리는 가능하지만, 협업을 위해서는 코드를 공유할 수 있는 플랫폼이 필요합니다.\n대표적인 플랫폼으로는 GitHub, GitLab, Bitbucket이 있습니다.\n✅ GitHub: 가장 대중적인 Git 플랫폼으로, 오픈소스 프로젝트가 많고 무료 저장소를 제공합니다.\n✅ GitLab: CI/CD(자동 배포) 기능이 강력하여 DevOps 환경에 적합합니다.\n✅ Bitbucket: Jira와의 연동이 쉬워 애자일 개발 환경에서 자주 사용됩니다.\n이 중에서 GitHub이 가장 널리 사용되므로, 처음에는 GitHub을 중심으로 익히는 것이 좋습니다.\n\nGithub 가입하신분은 팔로우 부탁드려요 ^^\n옥진석 Github 바로가기\n2. GUI 기반 Git 클라이언트\nGit은 기본적으로 터미널에서 명령어를 사용하여 조작하지만, 보다 직관적으로 관리하고 싶다면 GUI 기반의 Git 클라이언트를 활용할 수 있습니다.\n✅ GitKraken: 직관적인 UI를 제공하며, 시각적으로 브랜치를 관리하기에 용이합니다.\n✅ SourceTree: Atlassian에서 제공하는 무료 Git 클라이언트로, Bitbucket과의 연동이 강점입니다.\nGUI 클라이언트는 브랜치 구조를 한눈에 확인할 수 있어, Git을 처음 배우는 분들에게 특히 유용합니다.\n3. GitHub 전용 클라이언트\nGitHub을 사용할 때 편리한 GitHub 공식 GUI 클라이언트도 있습니다.\n✅ GitHub Desktop: Git 명령어를 몰라도 기본적인 Git 기능을 쉽게 사용할 수 있도록 도와줍니다.\n명령어 기반 CLI(터미널)에 익숙하지 않다면, GitHub Desktop을 먼저 사용해 보는 것도 좋은 방법입니다.\n4. VS Code 플러그인\n개발 환경에서 Git을 보다 편하게 사용하고 싶다면 VS Code의 Git Extensions을 활용할 수 있습니다.\n✅ GitLens: 파일이 언제, 누구에 의해 수정되었는지 확인할 수 있습니다.\n✅ Git Graph: 브랜치 및 커밋 로그를 시각적으로 표시합니다.\n✅ GitHub Pull Requests: VS Code에서 바로 PR(풀 리퀘스트)을 관리할 수 있습니다.\n이러한 확장 프로그램을 활용하면 Git을 더욱 편리하게 사용할 수 있습니다.\n\n💡 그래서 Git을 어떻게 사용하는데?\n\n\nGit 기본 명령어부터 익히기\n\ngit clone, git add, git commit, git push, git pull 같은 기초 명령어를 익히는 것이 중요합니다.\n\n\n\n브랜치를 적극 활용하기\n\nmain 브랜치에서 직접 개발하지 않고, feature-브랜치를 생성하여 작업하는 습관을 들이는 것이 좋습니다.\n\n\n\nPR(Pull Request)과 코드 리뷰 익히기\n\n코드 변경 사항을 공유하고 피드백을 받는 과정이 Git 협업의 핵심입니다.\n\n\n\n명확한 커밋 메시지 작성하기\n\n&quot;fix: 로그인 버그 수정&quot;, &quot;feat: 회원가입 기능 추가&quot;처럼 한눈에 변경 사항을 이해할 수 있도록 작성하는 것이 좋습니다.\n\n\n\n충돌(Conflict)은 두려워하지 않고 직접 해결하기\n\n충돌이 발생하면, 차분하게 코드 변경 내용을 비교하고 합치는 연습이 필요합니다.\n\n\n\n\n마무리…\nGit과 Git 도구는 신입 개발자가 협업을 시작할 때 가장 먼저 익혀야 할 필수 기술입니다.\n처음에는 어렵게 느껴질 수도 있지만, 사용하다 보면 Git이 없는 개발 환경이 오히려 더 불편하게 느껴질 것입니다.\n다음은 자주 사용하는 Git 설치 방법과 명령어, 그리고 협업시 서로 충돌없이 Git을 다루기 위한 Branch전략에 대해서 알아아보도록 하겠습니다.\n\n👉 다음 편: Git 설치와 기본 명령어"},"a_project/git/git-guide-2":{"slug":"a_project/git/git-guide-2","filePath":"a_project/git/git-guide-2.md","title":"설치와 기본 명령어","links":[],"tags":["Dev","Git","GitHub","Collaboration"],"content":"👉 이전 편 : Git의 개념과 Git Tool\n\n이전 글에서는 Git을 왜 사용하는지와 Git을 사용하기 편리하도록 하는 도구들에 대해서 알아보았습니다.\n이번 글에는 직접 Git을 설치하여 Github과 연동하고 코드를 Github에 저장하고 불러오는 방법에 대해서 알아보도록 하겠습니다.\n\n1. Git 설치하기\nGit은 OS마다 설치방법이 서로 상이합니다. 자신의 개발 환경에 맞는 방법으로 Git을 설치해주세요.\n\nWindows\n\nGit 공식 홈페이지에서 최신 버전을 다운로드합니다.\n\n\n  \n    \n  \n  \n    \n  \n\n- 설치할 때 기본 설정을 유지하면서 진행합니다. 대부분의 설정을 Next하시면 되겠습니다.  \n  내용이 궁금하시다면 읽어보시는걸로\n- cmd 터미널을 열어서 `git --version` 명령어를 통해 정상적으로 설치되었는지 확인합니다.\n\n    \n\n해당 내용이 뜬다면 설치가 완료된 것입니다.\n\nmacOS\nbrew install git\n설치 후 버전 확인:\ngit --version\n\nLinux (Ubuntu 기준)\nsudo apt update\nsudo apt install git\n설치 후 버전 확인:\ngit --version\n\n2. GitHub 계정생성과 Git 연동\n\n그다음으로 해야 할 작업은 Git과 연동을 시킬 Github 계정과 Repository를 만들어 줘야 합니다.\nRepository는 저장소라는 의미로, Git에서 프로젝트의 파일과 변경 이력을 관리하는 공간입니다.\n\n1. GitHub 계정 생성\n\nGitHub 공식 홈페이지에서 Sign up 버튼을 눌러 계정을 생성하세요.\n이메일 인증 후 Sign in합니다.\n\n\n2. 새 Repository 생성\n\n\n로그인을 하게 되면, SNS의 메인 화면처럼 내 Dashboard가 기본으로 보이게 됩니다.\n여기서 우측 상단의 프로필 아이콘 → Your repositories → 우측 상단의 초록색 New 버튼을 클릭해 줍니다.\n\n\nRespository name을 입력해줍니다. Repo명은 보통 my-repo 와 같이 케밥케이스를 사용합니다.\n  \n  선택 사항 설정\n  \n\n어떠한 Repo인지 소개해주는 **Description**을 작성합니다. ex) “This is my first GitHub repository.”\n공개 여부 선택\n\n\n    Public : 누구나 볼 수 있음 - 흥미로운 프로젝트는 언제든지 탈취 및 해킹이 가능하단점을 명심하세요!\n    Private : 본인과 초대한 사람만 접근 가능하도록 설정합니다.\n\n- **`.gitignore`**는 Commit시에 제외할 파일 형식을 지정해주는 파일입니다. 보안이 중요한 파일이나, 용량이 큰 라이브러리 등을 gitignore에 등록하여 업로드를 제외해줍니다.\n  \n  \n\n\n마지막으로 Create repository 버튼 클릭\n\n\n\n3. 생성한 Repository를 로컬에 Clone하기\nRepo를 생성하게 되면 아래와 같은 화면으로 이동하게 됩니다.\n\n    \n\n이 화면에서 알려주는 방식으로 Git을 등록해도 되지만, 저는 설명하는 방법과는 다른 방법으로 접근해 보겠습니다.\n우선, Repository 경로 ( github.com/user_id/repo_name.git ) 를 한번 복사해 봅시다.\n그리고 해당 레포를 저장할 폴더나 바탕화면으로 이동해 줍니다.\n바탕화면에서는 우클릭으로 cmd를, 폴더에서는 주소창에 cmd를 검색을 해줍니다.\n\n    \n\n그러면 해당 폴더의 주소를 가진 cmd화면으로 바로 이동이 가능합니다.\n\n이제 cmd 창에 git clone github.com/user_id/repo_name.git 을 입력하면 Git과 GitHub이 연동이 안되었다고 뜹니다.\nGit과 GitHub을 연동하기 위해선 현재 로컬 기기에 사용자의 email과 name을 등록 해주어야 하기 때문입니다.\n아래의 내용을 cmd에 입력해줍니다.\n# github에 회원가입한 이메일을 입력해주세요\ngit config --global user.email &quot;your.email@example.com&quot;\n \n# 커밋시 본인 식별을 할 수 있는 닉네임을 입력해주세요.\ngit config --global user.name &quot;Your Name&quot;\n이후 다시 한번 클론을 하게 되면, Github와 연동을 하겠다는 안내문구가 나오며, Git과 연결된 Repository가 생성이 되는 것을 확인 할 수 있습니다.\n\n해당 폴더에 들어가면 아무 파일이 없는데, 폴더 숨김을 제거하여 .git 폴더를 확인해주세요.\n\n폴더 상단의 점 3개 버튼을 눌러서\n설정창열기 → 보기 탭 → 고급 설정 아래로 스크롤 하다보면 숨김 파일, 폴더 및 드라이브 표시 체크 → .git 폴더 확인\n\n    \n\n이제 Repo가 성공적으로 클론이 되었습니다!\n\n3. Git 기본 명령어 : 커밋, 푸시, 풀\nGit을 사용할 때 가장 기본적으로 수행하는 작업은 파일을 추가하고(commit), 원격 저장소에 업로드(push)하고, 최신 변경 사항을 가져오는(pull) 것입니다.\n\n1. 작업한 파일 커밋 및 푸시\nGit에서는 변경된 파일을 추적하고 저장하기 위해 **커밋(commit)**을 사용합니다.\ncd repository  # 작업할 레포지토리로 이동\n \n# 파일 생성, 수정, 삭제 작업 진행\n \n# 변경된 파일 확인\ngit status\n \n# Git에 수정한 파일 추가\ngit add readme.txt\n \nor\n \n# Git에 수정한 파일 전체 추가\ngit add .\n \n# Commit\ngit commit -m &quot;첫 번째 커밋&quot;\n \n# 오리진의 main branch에 push\ngit push origin main\n \n# 여기까지 로컬 git에서 오리진에 올리기위한 작업이라고 보시면 되겠습니다.\n# 1. git add . 을 통해 변경된 파일을 박스에 담아서\n# 2. git commit -m &quot;&quot; 을 통해 이름표를 붙인후\n# 3. git push를 통해 main 브랜치 주소로 보내기!\n💡 언제 사용할까?\n\n프로젝트에 새로운 파일을 추가했을 때\n기존 파일을 수정한 후 변경 사항을 저장하고 싶을 때\n로컬에서 변경한 내용을 오리진에 기록하여, 후에 변경 내역으로 돌아가고 싶을 때\n\n📌 추가 설명\n\ngit add readme.txt → 특정 파일만 추가\ngit add . → 변경된 모든 파일 추가\ngit commit -m &quot;메시지&quot; → 커밋 메시지를 포함하여 저장\n\n⚠️ 주의사항 : 커밋 메시지는 변경 사항을 쉽게 이해할 수 있도록 의미 있는 내용으로 작성하는 것이 중요합니다.\n\n&quot;버그 수정&quot; → ❌\n&quot;로그인 기능 오류 수정&quot; → ✅\n\n\n2. 최신 코드 가져오기 (pull)\n다른 사람이 원격 저장소에 업로드한 최신 변경 사항을 가져오려면 pull 명령어를 사용합니다.\n# main branch를 가져와라!\ngit pull origin main\n💡 언제 사용할까?\n\n다른 팀원이 내가 작업중인 저장소( branch, 여기서는 main branch )나 상위 Branch를 업데이트했을 때\n원격 저장소에서 최신 상태로 동기화하고 싶을 때\n내가 작업하기 전에 최신 코드를 가져와 충돌을 방지하고 싶을 때\n\n📌 추가 설명\n\ngit pull = git fetch + git merge\n\ngit fetch : 원격 저장소의 변경 사항을 가져오기만 함\ngit merge : 가져온 변경 사항을 현재 브랜치에 병합\n\n\n만약 충돌이 발생하면 git add . → git commit → git push 를 통해서 수정한 코드를 오리진에 보낸 후 Conflict난 부분을 직접 수정 해야 합니다.\n\n⚠️ 주의사항:\n\n내 로컬 코드와 원격 저장소 코드가 다르면 충돌이 발생할 수 있음\ngit pull --rebase를 사용하면 더 깔끔한 히스토리를 유지할 수 있음\n\n\n4. 자주 발생하는 에러 - LF (줄바꿈) 오류 해결\n운영체제마다 줄바꿈 방식이 달라(Git에서 Windows는 CRLF, macOS/Linux는 LF 사용) 줄바꿈 변환 문제가 발생할 수 있습니다. 특히 Windows + Eclipse 환경에서는 자동 변환으로 인해 예상치 못한 변경 사항이 생길 수 있습니다.\n\n1. 현재 설정 확인\ngit config --global core.autocrlf\n\n\ntrue → 체크아웃 시 CRLF → LF 변환, 커밋 시 LF → CRLF 변환 (Windows 기본값)\ninput → 체크아웃 시 변환 없음, 커밋 시 LF 유지 (권장)\nfalse → 변환 없음 (macOS/Linux 기본값)\n\n\n2. 해결 방법 (권장 설정)\nWindows에서도 LF를 유지하려면:\ngit config --global core.autocrlf input\n이 설정을 적용하면 Git에서 자동 변환 없이 LF 형식을 유지하여 크로스 플랫폼에서 일관된 코드 관리를 할 수 있습니다.\n\n3. 프로젝트별로 설정하려면?\n.gitattributes 파일을 추가하여 특정 확장자의 줄바꿈을 고정할 수도 있습니다.\n* text=auto\n*.sh text eol=lf\n*.bat text eol=crlf\n\n마무리…\n이번 글에서는 혼자서 Git을 다루는 방법에 대해서 알아보았습니다.\r\n그러나 우리가 Git을 사용하는 이유는 협업을 하기 위함이죠?\r\n다음시간에는 서로의 코드의 충돌을 예방하면서도, 버전관리와 배포에 용이한 브랜치 전략에 대해서 알아보도록 하겠습니다.\n\n👉 다음 편 : Git Branch"},"a_project/git/git-guide-3":{"slug":"a_project/git/git-guide-3","filePath":"a_project/git/git-guide-3.md","title":"Git Branch 명령어","links":[],"tags":["Dev","Git","GitHub","Collaboration"],"content":"👉 이전 편 : Git 설치와 기본 명령어\nGit 브랜치는 여러 명의 개발자가 서로 영향을 주지 않고 동시에 작업을 할 수 있게 하며,\r\n브랜치가 특정 기능이나 이슈에 대응하여 작업을 추적하고 버전 단위로 관리하여 프로젝트 관리와 배포의 안정성을 높여줍니다.\r\n오늘은 주요 명령어가 내용이 많기때문에 먼저 설명드리고 그 아래에 전략을 살펴보도록 하겠습니다.\n\nGit Branch의 주요 명령어\n우선 브랜치를 조회하고 생성, 이동을 해보도록 합시다.\n\n\n브랜치 목록 확인\ngit branch\n \n-- 원하는 branch가 뜨지않는다?\ngit fetch ( 동기화 )\n\n\n새로운 브랜치 생성 ( 이동 X )\ngit branch 브랜치명\n \nex) git branch feature/signup\n \n-- 현재 브랜치 (main)\n-- 브랜치 생성\n-- git branch // 브랜치 목록 확인\n   main * // 아스타리카는 내가 현재 있는 위치를 뜻합니다.\n   feature/signup\n\n상위 브랜치를 그대로 복사하여 새로운 분기가 생기니, 항상 상위(현재) 브랜치의 위치를 확인합시다.\n보통은 main 아래에 develop 브랜치를 분기해서 한 후, 해당 브랜치에서 feature 브랜치를 분기해서 작업을 진행합니다.\n\n\n\n해당 브랜치로 이동\ngit checkout 브랜치명\n \nex) git checkout feature/signup\n\n\n새로운 브랜치로 생성하고 바로 이동\ngit checkout -b 브랜치명\n \nex) git checkout -b feature/signup\n \n-- 현재 브랜치 (main)\n-- 브랜치 생성\n-- git branch // 브랜치 목록 확인\n   main\n   feature/signup * // 아스타리카는 내가 보고있는 위치를 뜻합니다.\n\n\n작업 후 커밋을 해야 로컬에서 생성한 브랜치가 서버로 올라가게 됩니다.\n-- 파일 작업 이후\ngit push origin feature/signup\n\n절대 git push origin main이나 git push origin develop하지 말것\n담당자는 main과 develop에 Protected 작업을 해줍시다. ( push해도 변경이안됨 )\n\n\n\n\nPull Request ( == Merge Request )\nPull Request 줄여서 PR은 ( GitLab에서는 MR이라고 합니다. ) 개발과 테스트가 끝난 코드를 실제로 배포되고있는 Main 브랜치나 Release( 배포 ) 브랜치에다가\r\n어떤 작업을 한 커밋인지, 어떤 문제가 발생했었는지, 어떻게 해결을 하였는지 등을 보기 쉽게 기술하여 담당자에게 제출하는 작업입니다.\n이 작업을 통해 문제가 발생하더라도 빠르게 추적하여 에러를 해결 할 수 있기 때문에 중요한 Branch에는 필수적인 작업입니다.\n그러면 어떻게 PR을 날릴 수 있느냐..\n해당 작업은 GitHub 웹페이지에서 진행합니다.\r\n브랜치에서 작업이 완료 한 후 commit을 하게 되면 웹페이지에 PR이 가능한 버튼이 생성이 됩니다.\n\n해당 버튼을 누르면\n\n위와 같은 화면이 나오는데 내용은 아래와 같습니다.\n\n내가 작업한 브랜치를 어디로 합치겠냐입니다. 팀이 약속한 컨벤션에 따라 적절한 브랜치를 선택해주세요.\n커밋 제목과 내용입니다. 해당 내용도 보고 받아야 주요 내용을 form 형식으로 약속하여 일관된 내용을 받으면 작업의 효율성이 높아집니다.\n변경 사항입니다. 해당 기능을 개발하기 위한 모든 변경사항과 contributor를 확인 할 수 있습니다.\n\n그 아래로 스크롤 해보면 수정된 모든 파일을 확인 할 수 있습니다.\n\n확인이 되었다면 위의 Create Pull Request를 눌러봅시다.\n그러면 최종 확인 창이 뜨게 됩니다.\n여기서 특정한 문제 ( 충돌 문제, Conflict ) 가 발생하지 않는다면 초록색으로 Merge 버튼이 뜨게 됩니다.\r\n만약 팀원이라면 버튼을 누르지 않는 여기까지가 작업 완료입니다.\nCreate Pull Request 까지 작업을 한 후 팀장님께 PR 날렸습니다~ 라고 보고드리면 됩니다.\n\n팀장이나 코드 리뷰어는 해당 소소 코드들을 분석하여 Merge할지 반려할지 판단을 하게 됩니다.\r\n최종적으로 안전한 코드라고 판단이 된다면 Merge를 눌러 아래와 같은 화면을 확인합시다.\n\n\nGit Branch 전략\nGit 전략은 관련된 블로그들이 아주 많이 있는거 같아요.\r\n개발자들이 주로 사용하는 Git 브랜치 전략에 대해서 공유드리고 글 마무리 하도록 하겠습니다.\ngit branch 전략"},"a_project/notion/collaboration-template-guide":{"slug":"a_project/notion/collaboration-template-guide","filePath":"a_project/notion/collaboration-template-guide.md","title":"노션 협업 템플릿","links":[],"tags":["Dev","Notion","Collaboration"],"content":"“오늘도 개발자가 안된다고 말했다.”\n밈처럼 사용되고있는 해당 글귀는 개발자들과 효율적으로 협업하는 방법을 다룬 책의 제목입니다.\n이 책은 서로 다른 전문성을 가진 사람들이 한 프로젝트에서 협력할 때 왜 소통에 어려움이 있는지를 보여줍니다.\n그렇다면 왜 협업은 어려울까요?\n여러 사람이 각자의 역할과 사고방식을 가지고 일하다 보면, 목표와 우선순위, 그리고 커뮤니케이션 방식에서 차이가 발생하기 마련입니다.\n기술적 제약, 일정의 압박, 그리고 각자의 경험과 관점이 다르기 때문에 정보 공유와 의사결정 과정에서 오해와 충돌이 생기기 쉽습니다.\n오늘은 이러한 문제를 해결하기 위해 제가 참여했던 프로젝트에서 유용했던 기능들을 묶어,\n간단한 노션 템플릿을 만들어서 공유드리고 사용법에 대해서 소개하고자 합니다.\n\n✅ 협업툴 템플릿 링크\n\n\n템플릿 복사 방법\n\n\n협업툴 템플릿 클릭\n우측 상단의 설정 버튼 클릭\n템플릿 복제하기 선택\n\n\n\n\n아래는 협업 템플릿에 대한 정의와 사용 방법입니다.\n\n트러블 슈팅 보드\n\n프로젝트 진행 중에 발생하는 문제나 이슈를 빠르게 파악하고 해결 과정을 공유할 수 있도록,\n트러블 슈팅 섹션을 보드 형태로 구성했습니다.\n보드에는 공통, 프론트, 백엔드, 서버와 같은 범주별 컬럼이 존재합니다.\n프론트엔드에서 발생하는 문제는 프론트 컬럼에 등록하고, 해결 과정을 카드에 상세히 기록해 둡니다.\n이렇게 문제 유형에 따라 구분해 두면, 팀원들이 필요한 정보를 한눈에 확인하고 중복된 이슈를 방지할 수 있습니다.\n또한 해결된 이슈는 별도의 컬럼으로 옮기거나 상태 표시를 해두면, 향후 유사한 상황이 생겼을 때 빠르게 참고할 수 있습니다.\n\n기능 명세서\n\n기능 명세서 페이지는 표 형식으로 구성되어 있으며, 기능을 추가하거나 변경할 때 필요한 정보를 체계적으로 정리하기에 용이합니다.\n기능 명세서에서는 구분, 세부 기능, 설명, 비고 등을 기록하여,\n프로젝트 내 모든 기능이 어떻게 동작하고 어떤 요구사항을 충족해야 하는지 명확히 정의합니다.\n이 문서는 기획자, 디자이너, 개발자 모두가 공유하는 기준점이 되므로, 업데이트 사항이 있을 때마다 즉시 반영해주는 것이 좋습니다.\n\nAPI 명세서\n\nAPI 명세서는 서버와 클라이언트 간 원활한 통신을 위한 중요한 문서입니다. 각 요청의 메서드(GET, POST, PUT, DELETE 등), API URL, path, 상세 설명, 그리고 프론트엔드 진행 상태 등을 표로 정리해 두었습니다.\n요청 시 필요한 파라미터, 응답 형식, 에러 처리 방식 등을 꼼꼼히 기록해 두면,\n팀원 간의 커뮤니케이션 오류를 줄이고 개발 속도를 높일 수 있습니다.\n또한, API 명세서와 함께 목 데이터(Mock Data)를 준비하면 백엔드 개발이 완료되기 전에도 프론트엔드 개발을 병렬적으로 진행할 수 있습니다.\n\n백엔드 개발자가 api를 구축하면서 전송하고 수집할 데이터의 형식을 미리 정의하는것을 목데이터라고 합니다.\n\n{\n  &quot;status&quot;: 200,\n  &quot;message&quot;: &quot;사용자 목록 조회 성공&quot;,\n  &quot;data&quot;: {\n    &quot;users&quot;: [\n      {\n        &quot;id&quot;: 1,\n        &quot;username&quot;: &quot;user1&quot;,\n        &quot;email&quot;: &quot;user1@example.com&quot;,\n        &quot;created_at&quot;: &quot;2023-03-15T09:30:00Z&quot;\n      },\n      {\n        &quot;id&quot;: 2,\n        &quot;username&quot;: &quot;user2&quot;,\n        &quot;email&quot;: &quot;user2@example.com&quot;,\n        &quot;created_at&quot;: &quot;2023-04-20T14:25:00Z&quot;\n      },\n      {\n        &quot;id&quot;: 3,\n        &quot;username&quot;: &quot;user3&quot;,\n        &quot;email&quot;: &quot;user3@example.com&quot;,\n        &quot;created_at&quot;: &quot;2023-05-10T11:15:00Z&quot;\n      }\n    ],\n    &quot;total_count&quot;: 3,\n    &quot;page&quot;: 1,\n    &quot;limit&quot;: 10\n  }\n}\n\n\n\n그 외 주요 섹션\nGit Rules\n버전 관리 시스템인 Git을 사용할 때 혼란을 방지하기 위한 규칙입니다.\n브랜치를 어떻게 나누고 관리할지, 커밋 메시지는 어떤 형식으로 작성할지 등을 명확히 정의해 놓음으로써 여러 개발자가 함께 작업할 때 발생할 수 있는 충돌( conflict )과 혼선을 최소화합니다.\n\nCode Convention\n코드 스타일, 변수 및 함수 네이밍 규칙, 그리고 IDE 설정까지 통일함으로써 모든 팀원이 일관된 코드를 작성할 수 있도록 돕습니다. 이는 코드 리뷰 시간을 단축시키고, 유지보수를 용이하게 만듭니다.\n\nERD\nERD는 데이터베이스의 구조를 시각적으로 표현한 것입니다.\n테이블 간의 관계와 각 필드의 특성을 한눈에 파악할 수 있어, 데이터 구조를 이해하는 데 큰 도움이 됩니다.\n\nFigma &amp; Flow Chart\n사용자 인터페이스 디자인과 사용자 경험 흐름을 시각화한 문서입니다. 개발자와 디자이너, 그리고 기획자 간의 소통을 원활하게 하며, 구현해야 할 기능의 흐름을 명확히 이해할 수 있게 해줍니다.\n\n추가로, Git에 익숙하지 않은 분들을 위해 다음 회고에서는 Git 사용법과 관련된 내용을 더 자세히 다루어보도록 하겠습니다.\n👉 다음 편 : Git의 개념과 Git Tool"},"a_project/z_etc/ai-code-review":{"slug":"a_project/z_etc/ai-code-review","filePath":"a_project/z_etc/ai-code-review.md","title":"지난 프로젝트를 통한 배움..","links":[],"tags":["Dev","Git","GitHub","AI","CodeReview","Collaboration"],"content":"다음 프로젝트를 앞두고…\n앞으로 진행할 핵심 프로젝트에서는 PR이 꽤 복잡해질 것 같다는 예감이 들었다.\n지난 프로젝트에서도 막판 이틀간 엄청난 양의 커밋이 올라왔고,\n그 와중에 코드 리뷰는 빠르게, 그리고 대충 넘어가는 경우도 많았다.\n나도 내가 짠 코드를 리뷰 없이 메인에 넣으면서\n“아, 이거 나중에 어디서 터질 수도 있겠다” 싶은 불안함을 몇 번은 삼켰다.\n그렇게 쌓인 코드가 실제로 발표 하루 전날 열댓 개의 버그로 돌아왔을 때,\n우리는 1분도 허투루 쓸 수 없다는 각오로 버그를 밀어냈다.\n돌이켜보면 팀원 모두 진짜 잘 싸웠다.\n그런데 ‘이런 방식의 고생’을 앞으로도 반복해야 할까?\n\n코드 리뷰는\n팀 프로젝트에서 ‘문화’가 아니라 그냥 ‘체력 싸움’처럼 느껴질 때가 있다.\n코드는 점점 복잡해지고, 기능은 촘촘해지는데, 리뷰는 시간에 쫓겨 대충 넘기게 되기 때문이다.\n특히 리뷰할 코드가 많아질수록 실수는 숨어들고,\n그 실수는 배포 직전에 모습을 드러내곤 한다.\n이번에는 그런 걸 좀 줄여보기 위해,\nPR 리뷰를 보조해줄 수 있는 도구가 뭐가 있을까 찾아보다 CodeRabbit이라는 서비스를 알게 됐다.\n\nCodeRabbit이란..\nGitHub에서 PR이 올라오면 자동으로 리뷰를 달아주는 AI 리뷰 도구다.\n기본적인 문법 오류나 스타일 체크는 물론,\n어느 정도 로직의 흐름까지 파악해서 피드백을 준다고 한다.\n“이 변수명은 다소 모호합니다” 같은 기본적인 지적 외에도,\n“이 로직은 특정 조건에서 무한 루프에 빠질 수 있습니다”\n같은 좀 더 깊은 문제도 짚어줄 수 있다는 얘기들이 있었다.\n어떤 로직이나 어떤 버전의 AI를 통해서 분석하는지 몰라서 구체적인 정밀도나 신뢰도는 단언할 수 없지만\n적어도 PR을 올렸을 때 ‘첫 번째 필터’처럼 걸러줄 수 있다면, 그 자체로 유의미한 역할을 할 수 있을 것 같다.\n\n마무리…\n리뷰는 결국 사람이 한다. 하지만 사람도 실수하고, 바쁘고, 피곤하다.\n그래서 CodeRabbit은 단순히 코드만 보는 게 아니라\n팀의 커뮤니케이션 흐름에도 영향을 준다고 생각한다.\n“이건 왜 이렇게 짰어?”라는 질문을 AI가 먼저 대신해주면\n리뷰어는 “그러면 이렇게 바꾸는 건 어때?”라는 제안을 더 쉽게 던질 수 있다.\n비난이 아닌 제안, 추궁이 아닌 공유로 리뷰의 톤이 바뀌는 여지를 만들어주는 것이다.\n결국 이런 도구를 고민하고 도입해보는 경험 자체가\n단순히 기능과 리뷰의 효율을 높이는 걸 넘어서\n더 나은 협업 방식을 익히고 실천하는 개발자로 성장하는 과정이라고 생각한다."},"b_backend/database/oracle-db-permission-guide":{"slug":"b_backend/database/oracle-db-permission-guide","filePath":"b_backend/database/oracle-db-permission-guide.md","title":"권한 관리와 적용 가이드","links":[],"tags":["Dev","SQL","Oracle","Database","Permission"],"content":"Keep\n오늘은 프로젝트에서 그렇게 자주 사용하지 않는 개념들임에도 불구하고 집중을 깨지않고 수업을 잘 따라갔다…\n또 이번주 초까지만 해도 일주일만에 오라클을 끝낼수있나? 생각이 들었는데,\n4일이 채 안되서 끝난거보면서 우리반 분들 수준이 다들 높구나라고 알게되었다.\n그리고 어제 회고록이 수업에서 방향도 많이 엇나가고 난해한 내용이였지만\n몇몇 분들이 봐주시고 유익했다고 해서 기분이 좀 좋았다..ㅎ🤭\n회고록도 처음 써보지만 나에게 도움이 꽤 많이 되고있있다.\n나는 난생 처음 보는 단어고 개념이라고 생각했었는데, SQLD랑 각종 DB 개념에 잔뜩 나오더라 ㅋㅋㅋㅠ\n그래서 앞으로도 나를위해서 또는 이 글을 읽을 누군가를 위해서 체력 되는한 최대한 열심히 쓰자라는 목표를 가지게 되었다..!!\nProblem\n오늘 배웠던 개념들은 처음 DB를 배울때 엄청 머리싸매면서 외웠었는데, 이후로 사용할 일이 전혀 없었더니 싹 다 까먹어서 다들 뉘신지.. 상태였다.\n잠시나마 나중에 프로젝트하면 뭐하지~ 이런 생각을 했던거에 대해서 반성을 하게 되었고, 어떻게 하지에 대해서 공부를 많이 해야함을 느꼈다.\n특히 DCL과 관련된 부분들은 팀장으로써 프로젝트 환경 설정 할때 많이 사용을 할테니, 주요 코드들은 수업 해주실때 바로바로 외워야 겠다고 생각이 들었다.\n프로젝트시 사용 할 수 있는 유저 생성과 권한 부여\n\n사용자 계정 생성\n\nCREATE USER &#039;jsock414&#039;@&#039;%&#039; IDENTIFIED BY &#039;password&#039;;\n    - %는 모든 ip에서 접속 가능하게 하겠다는 뜻이다.\n    - 특정 IP에만 부여하고 싶으면 %자리에 192.168.1.% 등으로 작성하면 된다.\n    \n\n기본 권한 부여 ( 테이블 조작, CRUD 작업 가능 )\n\n    생성한 유저에게 테이블을 조작 할 수 있는 권한을 주어야한다.\n    보통은 안정성을 위해 CREATE만 부여하는것을 권장한다고 한다.\nGRANT CREATE ON project_db.* TO &#039;jsock414@&#039;%&#039;;\n    - project_db.*는 project_db의 모든 테이블에 CRUD 작업을 가능케 하겠다는 뜻이다.\n    \n    팀 단위가 소규모이고 팀원들을 믿는다면 전체 권한을 다 부여해보자.\nGRANT CREATE, ALTER, DROP ON project_db.* TO &#039;jsock414&#039;@&#039;%&#039;;\n    \n    아래의 코드는 테이블 내부의 데이터를 조회, 삽입, 수정 삭제를 각각 부여한 코드이다.\nGRANT SELECT, INSERT, UPDATE, DELETE ON project_db.* TO &#039;jsock414&#039;@&#039;%&#039;;\n    \n    마지막으로 부여해줄 권한은 저장 프로시저이다.\n    저장 프로시저란 누군가가 정의해둔 SQL문을 함수로 만들어서 어딘가에 저장해 두는데,\n    이 저장한 함수를 사용 할 수 있는 권한을 준다는 것이다.\n    아마 사용할일이 앞으로도 많지않을꺼같아서 무조건 적용해보고싶다 아니면 넘어가도 될꺼같다.\nGRANT EXECUTE ON project_db.* TO &#039;jsock414&#039;@&#039;%&#039;;\n    \n    만약에 테이블과 관련된 모든 작업을 할 수 있는 권한을 부여하겠다면 아래와 같은 코드를 사용하면 되겠다.\nGRANT ALL PRIVILEGES ON project_db.* TO &#039;jsock414&#039;@&#039;%&#039;;\n    \n    또한 부여한 권한을 확인하는 방법은 SHOW를 사용한다.\nSHOW GRANTS FOR &#039;jsock414&#039;@&#039;%&#039;;\n    \n\n추가적으로 고려해봐야 하는 부분\n\n    DB를 담당한 운영자라면 DELETE를 REVOKE하는것에 대해서 고려를 많이 해야하는것 같다.\n    어떻게보면 협업의 효율을 저해 할 수 있지만, 그만큼 또 안전하다는거니까 팀원들을 잘 설득해보자.\nREVOKE DELETE ON project_db.* FROM &#039;jsock414&#039;@&#039;%&#039;;\n    \n    마지막으로 전해주고 싶은건 협업시에 필요한 마음가짐, 팀 컨벤션이다.\n    실제 현업에서 사용하는 컨벤션을 가져오고싶어서 몇몇의 기업을 조사를 해보았다.\n    \n    1. GOOGLE\n        최소 권한 원칙 : 팀원이 직접 DROP이나 ALTER 같은 명령어를 사용하지 않도록 제한\n    2. ORACLE\n        공용 계정 관리 및 보안 : 하나의 공용 계정 사용, project_user를 만들어서 관리하되, 비밀번호 공유 시 보안 유의\n    3. SAP\n        운영 환경에서는 DELETE 권한 제한 : 실수로 데이터 삭제하는 문제 방지\n    4. Neflix\n        필요한 경우만 CREATE / EXECUTE 허용 : 테이블을 변경하는 작업이 꼭 필요할 때만 테이블 생성과, 프로시저 호출 기능 사용\n    \nTry\n오늘 배운 Rownum을 바탕으로 프로그래머스의 문제를 하나 실습해보았다.\n문제 바로가기\n오랜 기간 보호한 동물(1)\n해당 문제는 프로그래머스의 3레벨 문제로 Oracle로 풀이를 할 시, 랭크를 매기지 못하면 풀지 못하는 문제이다.\n문제는 아래와 같다.\n\n아직 입양을 못 간 동물 중, 가장 오래 보호소에 있었던 동물 3마리의 이름과 보호 시작일을 조회하는 SQL문을 작성해주세요. 이때 결과는 보호 시작일 순으로 조회해야 합니다.\n\n문제 풀이 방법\n\n\n이름과 보호 시작일 조회 → SELECT NAME, DATETIME\n\n\n입양을 못 간 동물 찾기 → LEFT JOIN AIIMAL_OUTS + WHERE AO.ANIMAL_ID IS NULL\n\n\n보호 시작일 기준 정렬 → ORDER BY AI.DATETIME ASC\n\n\n상위 3개만 조회 → WHERE ROWNUM ≤ 3\n\n\n로직 자체는 무난한 문제였지만 ORACLE의 ROWNUM에 익숙하지 않은 상태였다면 심히 당황했을 문제이다.\n또한 새로운 조회 방식도 한번 찾아봤는데,\nFETCH라는 TOP-N 문법이 있었다.\nROWNUM과 기술적인 차이점으로는\nROWNUM은 실행 순서상 먼저 필터링 후 정렬 가능하지만, FETCH는 ORDER BY 이후에 위치하며, 정렬 후 필터링 한다.\n효율적인 방법으로는 ROWNUM이 효율적이나, FETCH가 더욱 직관적이고 안전하다고 할 수 있다.\n그리고 FETCH는 ORACLE 12C 이상에서 지원한다는 특징이 있다.\nfetch를 활용한 문제 풀이\nSELECT I.NAME, I.DATETIME\nFROM ANIMAL_INS I LEFT JOIN ANIMAL_OUTS O ON I.ANIMAL_ID = O.ANIMAL_ID\nWHERE O.ANIMAL_ID IS NULL\nORDER BY I.DATETIME ASC\nFETCH FIRST 3 ROWS ONLY;\nFETCH FIRST에는 ROWS ONLY 말고도\nWITH TIES를 사용한다거나 OFFSET이라는 페이징 처리 기능이 있으니 실습때 더욱 활용해보도록 하자..!"},"b_backend/database/sql-optimization":{"slug":"b_backend/database/sql-optimization","filePath":"b_backend/database/sql-optimization.md","title":"코드 최적화에 대한 고찰","links":[],"tags":["Dev","SQL","Oracle","Database","Optimization"],"content":"Keep\n기초적인 부분이라도 흘려듣지않고 부족했던 부분들을 채워나갔던것!  \nDB공부를 한동안 안했더니 Oracle과 SQL문법들을 많이 까먹엇었는데, 스마트 인재 개발원의 승환쌤의 실습 강의를 통해서 다중 서브쿼리나 DB의 제약조건들에 대해서 다시 한번 이해하게 되었다.\nProblem\n한번 더 고민하지 않았던 것..\n강의 중에 실수로 난이도가 조금 어려웠던 문제를 제출해주셨는데, 문제 해석을 제대로 하지않아 엣지 케이스를 발생시키는 풀이를 하였다.\n문제\n\n직원들중 제일 많이 받는 직원이 속한 부서의 급여와 같은 급여를 받는 직원의 이름과 급여를 출력하라!\n\n나는 이 문제를 단순하게 제일 많이 받는 직원의 같은 부서사람들이라고 판단을 하였고,\nselect department_id, first_name, salary\nfrom employees\nwhere department_id in (select department_id\n                        from employees\n                        where salary = (select max(salary)\n                                        from employees));\n이런식으로 풀이를 하였다.\n그러나, 실제로 문제를 분석해보면\n\n\n직원들중 제일 많이 받는 직원 ( 조건 )\n\n\n속한 부서의 급여 ( 출력 )\n\n\n같은 급여를 받는 직원(들) ( 조건 )\n\n\n으로 해석할수있다.\n이 풀이를 코드로 변환해보면\nselect first_name, salary\nfrom employees\nwhere salary in (select salary\n                 from employees\n                 where department_id in (select department_id\n                                        from employees\n                                        where salary = (select max(salary)\n                                                        from employees)));\n3중 서브 쿼리가 됨을 알수있다.\n\n풀이 코드와 나의 코드의 차이는,\n만약 max값과 동일한 사람이 여러 명이라고 했을 때 나의 코드는 해석이 틀렸기 때문에 가장 높은 급여를 가진 사람의 부서와 부서 내 사람들을 출력 한 반면\n풀이 코드는 max과 같은 SALARY라면 모든 부서의 직원을 다 출력 할 수 있다는 차이점이 있다.\n그러므로 문제를 제대로 이해하지 않은 채 코드를 작성 한 것이 제대로 문제를 보지 못한 첫 번째 원인이였고, 주어진 데이터셋이 표본이 적다보니 너무 단순하게 생각했던점이 두번째 원인이였다.\n앞으로 비슷한 유형의 문제들을 많이 풀어보면서 요구사항을 놓치지 않는 능력을 많이 키워야 할 것 같다.\n\nTry\nProblem으로 부터 얻은 관점\n그래서 나는 더 놓친게 없는가? 라는 생각을 해보았다.\n\n놓친 부분\n\n\nNull DATA : 실제 DB였다면 NOT NULL 제약조건이 있음이 분명하지만, 교육용 데이터 셋는 그렇지 않다. salary나 department_id가 null일 경우를 고려해봐야 한다.\n\n\n최고급여를 받는 직원이 여러 부서에 있을 경우? : employees에는 없었지만 충분히 가능성 있는 조건이다 DISTINCT를 활용해서 중복된 직원을 제거해주어야 한다.\n\n\n\n해당 내용을 적용하여 개선된 코드\nSELECT first_name, salary\nFROM employees\nWHERE salary IN (\n            SELECT salary\n            FROM employees\n            WHERE department_id IN (\n                        SELECT DISTINCT department_id\n                        FROM employees\n                        WHERE salary = (\n                                    SELECT MAX(salary)\n                                    FROM employees\n                                    WHERE salary IS NOT NULL\n                                )\n                        AND department_id IS NOT NULL\n            )\n);\n\n맞다.. 엣지케이스를 억지로 만들다보니 억지스러운 감이 없지않아 있다.\n하지만 실제 DB의 다양한 조건들을 고려한다면 이런 답을 내려고 고민한 시간은 꽤나 유익한 투자였다.\n\n조건들은 크게 2가지로 볼 수 있는데\n우선은 데이터 정합성과 무결성의 위배이다.\n정합성이란, 데이터가 올바르게 유지되며, 원하는 결과를 정확하게 반영하는지를 의미하고, 비슷한 개념으로 데이터의 무결성이란, 데이터가 데이터베이스의 제약 조건을 만족하면서 정확하게 저장되고 유지되는 것을 의미한다.\n문제에서는 null값이 이미 입력이 되어 있었기 때문에 무결성을 위배했다고 볼 수 있고, 그러므로 Null처리를 하지 않는다면 정합성을 위배했다고 볼 수 있기 때문에, Max(salary) 연산이나 department_id 필터링을 통해 제대로 된 연산을 해주어야 한다.\n따라서 조회 시 마다 이런 작업을 하고싶지 않다면, DB를 설계할때 얼마나 자주 조회와 연산을 하는지 등에 따라서 제약조건을 신중히 고려해서 구축해야한다.\n\n다음은 성능 향상이다.\n우리는 개발자로서 항상 마음속에 지니고있어야 하는 생각이 바로 효율과 성능이라고 생각한다. 물론 지금과 같은 데이터와 SQL문으로는 백만분의 1초도 감축을 못하겠지만 그것이나마 줄이려는 의도가 중요하다고 생각한다.\n\n아무튼.. 성능향상이라고 생각한 이유는\n서브쿼리가 3중이여서인데, 쿼리는 결국 전체 결과를 내려면 해당 테이블을 전체를 4번이나 조회를 해야한다. 그러나 한 과정마다 DISTINCT나 IS NOT NULL을 적용해서 데이터셋을 줄여나간다면 충분히 유의미한 성능향상을 이끌어 낼 수 있으리라 생각했다.\n\n또한 추가적으로 몰랏던 부분인데,\n지금처럼 department_id의 return이 단일인지 다중일지 확실하게 모르는 상황이라고 치면, IN 연산자를 쓰는게 물론 에러를 예방하는데도 중요하지만, 성능 향상에도 좋다고 한다.\n\nG 선생의 답변으로는\n1. 연산자 사용 시\n하나의 값을 찾은 후 해당 값을 기반으로 비교하는 방식이므로, 여러 부서가 있다면 각각 반복적으로 실행 될 수 있음\n→ Nested Loop이 발생\n2. IN 연산자 사용 시\nRDBMS는 IN 연산자를 사용할 때 인덱스 최적화 및 해시 조인 기법을 활용할수 있다고 한다.\n또한 다중 값을 batch로 처리하기 때문에 =을 여러 번 실행하는 것보다 효율적이라고 알려주셧다.\n무슨말인지 정말 모르겠지만.. 일단 좋다고하니 알아둬야할거같다.\n\n주요 단어들만 한번 정리하고 회고를 마쳐보자..!\nNested Loop ( 중첩 루프 )\n중첩 루프 조인은 두 개의 테이블을 조인 할 때, 한 테이블을 iteration하면서 다른 테이블과 비교하는 방식이다.\n그래서 위와 같은 상황속의 = 연산자는 2중 for문을 돌리기 때문에 데이터 양에따라서 성능이 저하된다고 보인다.\n해시조인\n해시 조인은 데이터베이스에서 두 개의 테이블을 조인할 때 사용하는 알고리즘 중 하나이다.\n기본 원리로는 서브쿼리의 결과를 컴퓨터 메모리의 해시 테이블로 변환을 하는것인데, 이때 작은 테이블의 데이터를 키로 해서 Key-Value 형태를 가진 해시 주소를 만들어 준다.\n그 후 메인이 되는 테이블에서 데이터를 하나씩 읽으면서, 해시 테이블에서 매칭되는 값을 찾아오는것이다.\n해시(Key-Value)에 대해서는 알고리즘을 공부하다가보면 자연스럽게 알게될것이다..!\nBatch 처리\nBatch란 한번에 여러 개의 데이터를 처리하는 방식이다.\n즉, 쿼리를 여러 번 실행하는 대신 한 번에 여러 개의 데이터를 처리하여 성능을 향상시킨다.\n근데 batch라는 놈이 어떻게 한번에 여러개의 작업을 처리 할 수 있는 방식에 대해서는 이해를 할 수가 없었다. 데이터 베이스 내부에서 특정 SQL문을 실행할때 자동으로 처리된다거나, JDBC, JPA등의 어플리케이션에서 API를 동해서 자동으로 처리가 된다고 한다…"},"b_backend/database/what-is-postgresql":{"slug":"b_backend/database/what-is-postgresql","filePath":"b_backend/database/what-is-postgresql.md","title":"PostgreSQL...?","links":[],"tags":["Dev","SQL","PostgreSQL","Database","Optimization"],"content":"요즘 데이터베이스 시장은…\n최근 데이터베이스 시장에서는 오픈소스 DBMS가 빠르게 부상하고 있다.\n이전에는 Oracle, Microsoft SQL Server, IBM DB2 같은 상용 DBMS가 시장을 주름잡았는데, 최근 10년 사이에 기술력의 발전으로 오픈소스 DB에 대한 인식이 완전히 달라졌다.\n심지어 보안에 민감한 공공, 금융 등의 영역에서조차 기술 부채와 유연성의 장점으로 인해 오픈소스 DBMS를 적극 검토하기 시작했으니, 기존 상용 DB가 독점하던 시장 구조가 얼마나 많이 바뀌는지 알 수 있다.\n\n오픈소스 DBMS, 도대체 뭐가 그렇게 좋은거지?\n오픈소스 DBMS란 그냥 소스 코드가 공개되어 있어 누구나 자유롭게 사용하고, 고치고, 배포할 수 있는 데이터베이스 관리 시스템이다.\n나는 처음에 굉장히 의심스러운 방식이 아닌가..? 싶었는데 여럿 장점을 찾아보면서 유행하는데는 다 이유가 있구나 이해를 하게 되었다.\n\n투명성과 신뢰성 : 소스 코드가 공개되어 있어 보안 취약점이나 버그를 전 세계 개발자들이 함께 검토하고 해결할 수 있다.\n과거에는 오픈소스가 보안적으로 취약할 것이라는 우려가 있었으나, 실제로는 그 반대의 현상이 나타났다.\n광범위한 검토와 빠른 패치 사이클 덕분에 잠재적 문제가 더 신속하게 발견되고 수정된다.\n최근 Next.js와 같은 인기 오픈소스 프로젝트에서의 보안 이슈도 커뮤니티의 집단 지성을 통해 빠르게 대응되었으며, 이는 오픈소스 생태계의 자정 능력과 복원력을 증명한다.\n비용 절감 : 라이선스 비용 없이 쓸 수 있으니 초기 도입 비용이 확 줄어든다. G선생에세 물어보니 대략 Oracle을 사용하는 것 보다 약 94%정도 절감 할 수 있다고 한다.\n맞춤형 구성 : 기업이 진짜 필요한 기능만 골라서 쓸 수 있으니, 적정 엔지니어링을 유지 할 수 있다.\n\n특히 마지막 요소는 요즘 기업 환경에서 엄청 중요하다.\n상용 DBMS는 ‘올인원’ 패키지를 제공하지만, 대부분 기업은 그 중 일부만 실제로 쓴다.\n근데 오픈소스 DBMS는 핵심 기능만 기본으로 제공하고, 더 필요한 거 있으면 확장 모듈로 끼워 넣으면 되니까 ‘비용 대비 가치’가 훨씬 높다.\n\nPostgreSQL은…\n1986년 버클리 대학의 POSTGRES 프로젝트에서 시작된, 30년 넘은 역사를 가진 역사와 전통을 가진.. 한마디로 정의하자면 근본이 있는! 오픈소스 DBMS다.\n그 긴 시간 동안 ‘핵심에 충실하면서도 확장성은 무한하게’ 라는 철학을 꾸준히 지키며 오늘날을 위해 성장해왔다.\n이러한 철학은 위에서 말한 오픈소스의 장점들과 맞물려 현 시대의 가장 사용성이 높은 DBMS가 되는데 크게 일조를 하였다.\nDBMS와 관련된 자료를 찾다 보면 기업은 데이터베이스 고를 때 깊은 딜레마에 빠진다고 한다.\n상용 DBMS는 기능이 완벽하게 다 갖춰져 있지만, 그 비용은 가히 돈먹는 하마라고 불릴 수 있고,\n일반적인 오픈소스 DBMS는 비용은 적게 들지만 엔터프라이즈급 기능이 부족한 경우가 많다.\n하지만 PostgreSQL은 이 사이의 간극을 완벽하게 메꿔준다.\n오래된 역사에 알맞게 기본적인 데이터베이스 기능인 ACID 준수, 트랜잭션 관리, 복잡한 쿼리 처리 등등을 철저하게 갖추고 있다.\n당연히 직접적으로 비교 해봤을때 100% 기능을 구현한다라고 할 순 없다.. 하지만 그 100%의 기능을 전부 다 사용하는 기업이 얼마나 될까?\nPostgreSQL은 자칫 불필요한 기능을 채워넣기 보다는 ‘레고 블록’처럼 필요한 기능을 자유롭게 추가할 수 있는 확장성에 크게 집중하고 있다.\n예를 하나 들어보자면, 기존 상용 DBMS들은 대부분 정형화된 데이터(숫자, 문자열, 날짜 등)만 효율적으로 처리하도록 설계되었다.\n만약 새로운 형태의 데이터를 다루려면 비싼 추가 모듈을 구매하거나 복잡한 우회 방법을 사용해야 했다.\n하지만 PostgreSQL은 다르다.\nPostgreSQL은 기본적인 정형 데이터 뿐만 아니라, JSON, JSONB(더 빠른 JSON), XML과 같은 비정형 데이터와 배열, 범위 타입 등 다양한 데이터 타입을 지원한다.\n여기에 필요에 따라 확장 모듈을 붙이면 특화된 기능까지 활용할 수 있다.\n금융 회사처럼 시계열 데이터(시간에 따라 변화하는 데이터)를 다루고 싶다면 TimescaleDB를 추가하면 되며, 지도 앱처럼 위치 정보를 다뤄야 한다면 PostGIS를 붙이면 된다. 데이터가 너무 많아 서버 한 대로 감당이 안 되면 Citus로 여러 서버에 분산 처리할 수도 있다.\n빅데이터 분석 기사를 준비하고 있는 요즘.. 다양한 데이터 타입을 지원한다는게 정말 매력적인 기술 스택이 아닌가 생각이 들면서 내가 기업이라고 생각해도 이런 확장팩들이 무료에 가깝다니 선택을 안 할 이유가 있을까..!\n정리해 보자면,\n첫째, 비즈니스에 정확히 맞는 구성을 골라 쓸 수 있으니까 복잡성과 오버헤드를 확 줄일 수 있다.\n둘째, 회사가 성장하고 요구사항이 바뀌면 새로운 기능을 그냥 추가하면 된다. 미래를 위한 확장 경로가 완벽하게 열려있는 셈이다.\n많은 기업들이 PostgreSQL을 선택하는 이유가 이런 ‘현재 필요한 것만 쓰고, 나중에 필요한 건 나중에 추가하면 되는’ 유연성 때문이다.\n\n단점은 없을까..?\n물론 PostgreSQL도 장점만 있진 않다. 강력한 기능만큼 운영과 관리가 까다롭다는 문제가 있다.\n여러 설정과 확장 기능을 직접 이해하고 적용해야 하고, 문제가 생겼을 때 대처할 체계가 없으면 서비스 운영이 힘들어질 수 있다.\r\n단순하게만 생각해봐도 오픈소스는 상용 서비스랑 다르게 책임자도 없고 관리자도 없다.\n그렇기 때문에 데이터 암호화, 백업, 복구, 모니터링 같은 건 DB 엔진만으로는 해결이 불가능이고 , 별도 솔루션이나 클라우드 서비스를 도입해야 할 때가 있다고 한다.\n\n마무리…\n작년 말 Kotlin으로 앱 개발 프로젝트를 한 적이 있는데, Spring으로 서버 개발시간을 줄이기 위해 서버리스 서비스인 Supabase를 채택하게 되면서 연동 되어있는 PostgreSQL을 사용해본 적이 있다.\r\n그때 당시에는 PostgreSQL의 PL/SQL도 정말 익숙하지않고, 우리가 알고있는 Oracle, MySQL보다 잡다한 기능이 많아서 이렇게 복잡한걸 도대체 어떻게 써..! 하면서 욕을 엄청 했었는데,\n지금 돌이켜보면 이런 ‘복잡함’이 실은 PostgreSQL의 유연성과 확장성을 위한 필수요소였다는 걸 깨닫게 되었다. ( 내가 SQL은 거기서 거기지 하며 공부를 안하고 쓴게 문제제였다..! )\n아무튼.. 이제는 오픈소스 DBMS의 성장과 PostgreSQL의 부상은 그냥 일시적인 유행이 아니라 시장의 구조적 변화라고 봐야 한다.\r\n오픈소스 DBMS의 성장은 앞으로도 계속될 것이며, 그 성장의 중심에 있는 PostgreSQL가 앞으로 써내려갈 역사를 눈여겨 보자."},"b_backend/java/interface-abstract":{"slug":"b_backend/java/interface-abstract","filePath":"b_backend/java/interface-abstract.md","title":"Abstract과 Interface","links":[],"tags":["Dev","Java","Class","Interface"],"content":"추상 클래스: 기본 구현을 제공하는 설계 틀\n추상 클래스는 인스턴스화할 수 없지만, 공통된 필드나 메서드를 미리 구현해 두어 여러 하위 클래스들이 이를 상속받아 사용할 수 있도록 합니다.\n이 방법은 중복 코드를 줄이고, 공통된 동작을 한 곳에서 관리할 수 있는 장점을 제공합니다.\n동물 클래스 예시\n동물이라는 개념을 예로 들어보면, 모든 동물이 공통으로 가지는 특성(예: 이름, 소리내기)을 추상 클래스로 정의할 수 있습니다.\n다음 코드는 동물 클래스의 추상적 설계를 보여줍니다.\npublic abstract class Animal {\n    protected String name;\n \n    public Animal(String name) {\n        this.name = name;\n    }\n \n    // 각 동물이 구현해야 하는 소리내기 메서드\n    public abstract void makeSound();\n \n    // 모든 동물이 공통적으로 사용할 수 있는 기능: 이름 출력\n    public void printName() {\n        System.out.println(&quot;동물의 이름: &quot; + name);\n    }\n}\n이 추상 클래스를 상속받아 구체적인 동물 클래스(예: 개, 고양이 등)를 작성하면, 각 동물은 자신만의 소리내기 방식을 구현하면서도 공통 기능은 그대로 사용할 수 있습니다.\n차량 클래스 예시\n또 다른 예로, 다양한 종류의 차량을 다루는 시스템을 생각해 볼 수 있습니다.\n차량의 공통 기능(예: 시동 걸기, 정지하기)을 추상 클래스로 구현하면, 각 차량 타입은 고유의 시동 방식만 구현하면 되므로 코드의 중복을 방지할 수 있습니다.\npublic abstract class Vehicle {\n    protected String model;\n \n    public Vehicle(String model) {\n        this.model = model;\n    }\n \n    // 각 차량이 구현해야 하는 시동 걸기 기능\n    public abstract void startEngine();\n \n    // 모든 차량에서 공통적으로 사용할 수 있는 정지 기능\n    public void stop() {\n        System.out.println(model + &quot; 정지합니다.&quot;);\n    }\n}\n이처럼 추상 클래스를 활용하면, 공통된 기능은 한 곳에서 관리하고, 각 하위 클래스는 개별 특성만을 집중적으로 구현할 수 있습니다.\n사용자 인터페이스(UI) 컴포넌트 예시\nUI 프레임워크에서도 추상 클래스는 유용하게 사용됩니다\n예를 들어, 기본적인 UI 컴포넌트의 공통 속성과 동작(위치 정보, 렌더링 기능 등)을 추상 클래스로 정의하면, 버튼, 텍스트 필드 등 다양한 컴포넌트가 이를 상속받아 개별적인 기능을 추가할 수 있습니다.\npublic abstract class UIComponent {\n    protected int x, y; // 컴포넌트의 위치 정보\n \n    public UIComponent(int x, int y) {\n        this.x = x;\n        this.y = y;\n    }\n \n    // 각 컴포넌트가 직접 구현해야 하는 화면 렌더링 메서드\n    public abstract void render();\n \n    // 공통적인 이동 기능\n    public void move(int deltaX, int deltaY) {\n        x += deltaX;\n        y += deltaY;\n    }\n}\n이런 설계를 통해 UI 개발 시 공통된 기능은 추상 클래스에서 관리하고, 각 컴포넌트는 고유한 렌더링 방식만 구현하면 되어 효율적인 개발이 가능합니다.\n\n인터페이스: 규칙을 강제하는 약속\n인터페이스는 클래스들이 반드시 지켜야 할 메서드의 시그니처만을 선언해 두어, 각 클래스가 동일한 방식으로 동작하도록 강제합니다.\n즉, 인터페이스를 구현하는 클래스들은 정해진 메서드를 반드시 포함해야 하므로, 서로 다른 클래스 간에도 일관된 상호작용을 보장할 수 있습니다.\n결제 시스템 예시\n인터페이스는 클래스들 사이의 일관된 규칙을 강제하여, 다양한 구현체들이 동일한 방식으로 동작할 수 있도록 돕습니다.\n예를 들어, 다양한 결제 수단을 지원하는 애플리케이션을 설계할 때, 모든 결제 방식에 대해 공통 규칙을 정의할 수 있습니다.\npublic interface Payment {\n    // 결제 금액을 처리하는 메서드\n    void processPayment(double amount);\n \n    // 결제 성공 여부를 반환하는 메서드\n    boolean isSuccessful();\n}\n이 인터페이스를 기반으로 신용카드, 계좌이체, 모바일 결제 등 각 결제 방식에 대한 구체적인 구현 클래스를 작성할 수 있습니다.\n이처럼 인터페이스를 사용하면 여러 결제 방식 간에 동일한 약속을 유지할 수 있어, 시스템 확장이나 유지보수가 용이해집니다.\n로그 기록 예시\n또 다른 예로, 다양한 로그 기록 방식을 사용하는 시스템을 생각해볼 수 있습니다.\n로그 메시지를 기록하는 기본 규칙을 인터페이스로 정의하면, 콘솔, 파일, 혹은 원격 서버에 로그를 남기는 방식에 상관없이 일관된 인터페이스를 제공할 수 있습니다.\npublic interface Logger {\n    // 로그 메시지를 기록하는 메서드\n    void log(String message);\n}\n이와 같이 인터페이스를 활용하면, 새로운 로그 방식을 추가할 때 기존 코드에 큰 영향을 주지 않고도 확장이 가능합니다.\n\n마무리…\n인터페이스와 추상 클래스는 각각의 목적에 따라 서로 다른 장점을 제공합니다.\n실제 개발 현장에서는 이 두 가지 개념을 상황에 맞게 적절히 활용하는 것이 중요합니다.\n각각의 특성을 잘 이해하고 적용한다면, 코드의 유지보수성, 확장성, 그리고 가독성을 모두 향상시킬 수 있을 것입니다.\n이 글이 인터페이스와 추상 클래스의 개념을 실제 예시를 통해 이해하는 데 도움이 되기를 바랍니다."},"b_backend/java/java-module-system":{"slug":"b_backend/java/java-module-system","filePath":"b_backend/java/java-module-system.md","title":"모듈 시스템 이해하기","links":[],"tags":["Dev","Backend","Java","Eclips"],"content":"클래스를 생성하려고 하자마자..\nA package name must be specified for module. 라고 처음보는 에러가 떳다.\n\n패키지 명의 모듈을 위해서 지정되어야 한다. 라고하는데\nPackage에 뻔히 default라고 되어있을뿐만 아니라, 그 동안 무수하게 많은 클래스들을 defualt 패키지에 만들어왔었는데\n갑자기 안된다고 하니까 자바의 억까가 벌써부터 시작이구나 하는걸 느꼈다.\n승환쌤께서는 module-info.java가 해당 문제의 원인이라고 하셨다.\n답을 듣고나니 얘가 어떤 원리로 감히 class 생성을 막는가..? 라는 생각이 들더라.\n그래서 G선생을 통해서 추가적인 답변을 구해보았다.\n\n🔍 오류 발생 원인\nmodule-info.java는 Java 9에서 도입된 모듈 시스템(JPMS, Java Platform Module System)의 일부로, 프로젝트가 명확한 모듈 구조를 가지도록 강제하는 역할을 합니다.\n이 파일이 존재하면 모듈화된 프로젝트로 인식되며, 몇 가지 중요한 제약 사항이 생깁니다. 이 때문에 module-info.java가 있는 프로젝트에서 패키지 선언이 올바르게 되어 있지 않으면 A package name must be specified for a module. 같은 오류가 발생할 수 있습니다.\n자바의 모듈 시스템 때문에 문제가 발생했다고 한다.\n기존의 자바는 모듈 시스템이 아니라 Class를 중심으로 한 Classpath를 사용을 했기 때문에, default 패키지여도 해당 경로를 인식을 할 수 있었으나, 모듈 시스템이 도입이 되면서 package를 중심으로 조금 더 대규모 애플리케이션구축에 효율적이면서 보안이 중요한 프로젝트를 만들기 위해서 Modulpath를 강제하게 되었다고 보면 되겠다.\n\nClasspath의 문제점\n1. JAR Hell 문제발생\n\n  컴파일 시에 경로를 순차적으로 탐색하기 때문에, 같은 패키지 내에 있는 클래스가 여러 개 있을 경우 충돌거나 원하지 않는 클래스를 return할 가능성이 높다.\n\n2. 캡슐화 불가능하며 접근 제어가 약함\n\n  Java의 public 키워드는 Classpath기반에서는 완전히 공개되기 때문에, 개발자가 원하지 않는 클래스도 모든 곳에서 사용될 수 있음.\n\n3. Classpath는 실행 시간이 길어질 수 있음\n\n\n  Classpath는 실행될 때 해당하는 클래스가 어디에 있는지 전부 찾아야 함.\n\n\n  즉, Classpath에 포함된 모든 JAR 파일을 뒤져야 해서 속도가 느려질 수 있음.\n\n\n그러면 모듈 시스템은 어떻게 사용을 할 수 있는가?\nmodulepath를 쓰면서 다른 패키지들과 상호작용하려면 어떤 패키지를 공개할지 명시적으로 선언해야 한다.\n\n직접 명시 ( export ) 를 해보자!\n첫째, 먼저 modul-info.java에 운영하고자하는 패키지를 exports한다.\nmodule my.module {\n    exports com.example.mypackage;\n}\n둘째, com.example.mypackage 안에 있는 모든 클래스는 패키지 선언을 해주면 끝이다.\npackage com.example.mypackage;\n \npublic class MyClass {\n    // 클래스 내용\n}\n \n\n마무리…\n너무 간단하지 않는가? 프로젝트시에 module-info를 활용해서 개발을 한번 해보자..!\n개념을 보니 Spring Boot의 의존성 주입이나, Java project의 maven, gradle의 구조와 비슷한거 같다.\n앞으로 교육을 받아보면서 해당 내용들을 한번 잘 정리를 해봐야겠다.\n그렇다면 또 반대로 모듈 시스템을 사용하는 JAVA 버전에서는 default를 사용 할 수없는가?\n댓츠 논노 그렇지않다.\n바로 처음 승환쌤이 말씀해주신거 처럼 modul-info를 삭제하는 방법이다.\n앗 그러면 많은 문제가 발생하지 않느냐..??  \n할 수 있지만, 지금 당장은 대규모로 클래스와 모듈을 만들 상황이 없기에 과감하게 삭제를 해보자!"},"b_backend/python/list-and-loc":{"slug":"b_backend/python/list-and-loc","filePath":"b_backend/python/list-and-loc.md","title":"Pandas의 배열 참조 방법","links":[],"tags":["Dev","Python","Pandas","Library"],"content":"Pandas를 배우기 전까지…\n나는 데이터를 다룰 때 항상 하나씩 직접 보면서 처리하는방식에 익숙했다.\n그게 디버깅을 실시간으로 하며, 정확한 코드를 짜는거라고 생각을 했으니까..\n또한 내가 주로 사용했던 SQL과 JAVA에서는 배열이든 리스트든, 인덱스는 언제나 숫자였고, 그 숫자는 곧 위치를 의미했다. 특정 값을 찾고 싶다면 반복을 돌리거나 조건을 걸어 하나씩 비교하는 게 당연한 흐름이었다.\n하지만 Pandas의 데이터 프레임은 처음부터 다른 접근을 요구했다.\n인덱스를 라벨이라고 칭하며, 인덱싱과 슬라이싱에도\ndf[1:3], df.loc[1:3], df.iloc[1:3] 라는 새로운 문법들이 등장했다.\n\n불리언 인덱싱은 그나마 감이 온다\n그 와중에 좀 적응이 된 내용은 불리언 인덱싱이다.\n조건을 주고, 그 조건에 맞는 행만 추려내는 방식은 마치 SQL의 WHERE절처럼 느껴진다.\ndf[df[&#039;score&#039;] &gt; 85]\n이 한 줄이 말하고자 하는 의도는 명확하다.\nscore가 85보다 큰 행들만 골라내라.\nPandas가 내부에서 [False, True, True] 같은 불리언 배열을 만들어 필터링한다는 걸 알고 나면,\n구조도 어느 정도 납득이 간다.\n다만, 여기서도 .loc을 함께 쓰는 것이 더 안전하다는 말을 듣고 나면 또 고민이 생긴다.\n“왜 .loc을 붙여야 하지?”, “df[조건]만으로는 부족한가?” 같은 의문이 연달아 따라온다.\n\nloc는 왜 이렇게 생겨먹었나..\n.loc은 겉보기에 그냥 슬라이싱 문법처럼 생겼다.\ndf.loc[10:11] 같은 코드를 보면, 딱히 낯설 게 없어 보인다.\n그런데 실제로 써보면, 이건 단순한 슬라이싱이 아니다.\nloc는 어떤 값을 ‘찾는 방식 자체’가 다르다.\n일반적인 인덱싱은 순서대로 값을 자른다.\n슬라이싱이면 앞에서부터 몇 번째, 몇 번째까지 자른다는 흐름이 명확하다.\n그런데 .loc은 그게 아니다.\ndf.loc[df[&#039;score&#039;] &gt; 85].loc[11]\n여기서 무슨 일이 일어나는가..?\n\n첫 번째 .loc[df[&#039;score&#039;] &gt; 85]에서 조건을 만족하는 행 전체를 필터링한다.\n그 결과가 새로운 DataFrame이 된다.\n그 위에서 다시 .loc[11]을 하면, 그 결과 내부의 인덱스 라벨 11을 탐색하게 된다.\n\n한 줄짜리지만 실제로는 불리언 인덱싱 → 결과 슬라이싱 → 하위 추출이라는\n세 단계가 압축돼 있는 셈이다.\n이게 .loc이 헷갈리는 진짜 이유였다.\n탐색 흐름이 연속적이지 않고, 중간 결과에 따라 탐색 기준이 달라지며,\n그 와중에도 문법은 너무 간단하게 생겨서 실수하기 쉽다.\n숫자라서 헷갈린 게 아니다.\n탐색 자체가, 사고 흐름 자체가 낯설었던 거다.\n\n마무리..\nnumpy와도 마찬가지로, 내가 헷갈렸던 건 문법 그 자체보다도 사고 방식의 차이였다.\n그 추상화가 처음엔 낯설고 불편했지만,\n하나씩 해석해보며 익숙해지다 보니 왜 이렇게 만들었는지도 조금씩 이해가 되기 시작했다.\n내가 익숙하지 않았던 건 문법이 아니라, 그 수단을 받아들이는 사고의 전환이었을지도 모른다."},"b_backend/python/whit-is-numpy":{"slug":"b_backend/python/whit-is-numpy","filePath":"b_backend/python/whit-is-numpy.md","title":"추상 사고력이 중요한 이유","links":[],"tags":["Dev","Python","Numpy","Library"],"content":"나는 자바로 개발을 시작했기 때문에…\n데이터를 하나하나 반복문으로 직접 순회하고 조건을 걸며 처리하는 방식에 익숙하다.\nfor (int i = 0; i &lt; arr.length; i++) {\n    if (arr[i] &gt; 3) {\n        ...\n    }\n}\n이게 익숙했고, 이게 명확하다고 느꼈다.\n그런데 최근 배운 Numpy는 그 고정관념을 깨어주었다.\narr[arr &gt; 3]\n너무 짧고, 너무 간단해서 오히려 불편하다..\n생각을 코드로 짠다는 느낌보다 전체적으로 계산을 한 뒤에 계산값을 조건으로 던진다는 느낌이었다.\n자바에서는 내가 로직의 흐름을 제어한다.\n조건문, 반복문, 변수 선언 등 모든 게 눈에 보인다.\n반면 오늘 배운 넘파이는 데이터에 대한 조건만을 선언하기에 상당히 이해하기 힘들었다.\n이해가 안되니 외워지지도 않았다…\nmovie[movie[:, 0] == 1][:, 2].mean()\n이렇게 편리해보이는 코드도, 사실상 공책에다가 손으로 로직을 열심히 짜서\n코드를 작성하였기때문에 어떻게보면 엄청난 추상화가 된 것을 알 수 있다.\n로직을 다 짠후에 코드를 칠 때 조차\n문법이 익숙하지 않아서 의심이 들었고, 그래서 중간 결과를 계속 찍어보며 확인했다.\n### 무수한 의심...\nmovie_ids = np.unique(movie[:, 1])\nprint(movie_ids)\n \nmovie_rate = []\n \nmovie_mean = movie[movie[:, 1] == 1]\nprint(movie_mean)\nmovie_mean = movie_mean[:, 2]\nprint(movie_mean)\nmovie_mean = movie_mean.mean()\n \nfor movie_id in movie_ids:\n    movie_mean = movie[movie[:, 1] == movie_id][:, 2].mean()\n    movie_rate.append([movie_id, movie_mean])\n \nprint(movie_rate)\nmovie_ratings = np.array(movie_rate)\nprint(movie_ratings)\n \n그 과정에서 깨달은 건,\n넘파이는 단순히 짧은 게 아니라 데이터 전체를 단위로 처리하는 방식이라는 점이다.\n이 과정이 익숙해진다면 대규모 데이터 처리에 특화되었다는게 무슨말인지 이해가 되지 않을까…\n\n생각보다 잘 설계된 추상화\n불리언 인덱싱, 슬라이싱, 타입 변환을 모두 한 줄에 담을 수 있다는 건\n처음엔 부담이었지만, 조금만 익숙해지면 오히려 명확하게 의도를 표현할 수 있는 수단인 것 같다.\n \nuser_mean_arr[user_mean_arr[:, 1] &gt;= 4][:, 0].astype(int)\n이런 구문이 처음엔 낯설지만,\n실제로는 “평균 평점이 4 이상인 사용자들의 ID만 정수형으로 뽑는다”는 명확한 뜻을 담고 있다.\n결국 익숙하지 않았던 건 문법 자체가 아니라, 배열을 전체 단위로 사고하는 방식이었다.\n\n자바와 넘파이의 구조적인 공통점\n넘파이를 계속 이해하려고 노력하다 보니, 처음엔 몰랐던 자바와의 닮은 점도 보이기 시작했다.\n넘파이 배열은 단순한 파이썬 리스트가 아니라, 고정 타입의 연속적인 메모리 블록이다.\n이건 자바의 배열과 유사하다.\n\n같은 타입만 저장 가능하고\n메모리상에 인접하게 배치되어 있으며\n슬라이싱 시에는 뷰(View)를 만들어 불필요한 복사를 피한다\n\n결론적으로, 문법만 제대로 익힌다면 특정 조건에서 자바와 같은 사고 방식으로\n더욱 간결하고 가독성 좋은 개발을 경험 할 수 있다는 뜻이다.\n\n마무리…\n넘파이.. 아직까지 너무 불편하다.\n“왜 이렇게 쓰지?”라는 생각이 수시로 들었고, 여전히 자바식 사고에서 완전히 벗어나진 못했다.\n그러나 회고를 하다보니\n어느정도 넘파이가 문법적으로만 단축을 해둔게 아니라, 구조적으로 효율적이라는 걸 받아들이게 됐다.\n\n추상화된 도구는, 결국 내가 할 수 있는 일을 더 빠르고 명확하게 해준다.\n\n그걸 믿고, 천천히 따라가면 이 낯선 도구도 결국 내 손에 익게 된다는 걸 느낀 실습이었다."},"d_certification/big-data-analysis/big-data-analysis-1":{"slug":"d_certification/big-data-analysis/big-data-analysis-1","filePath":"d_certification/big-data-analysis/big-data-analysis-1.md","title":"빅분기 시작!","links":[],"tags":["Dev","Big-Data-Analysis","Certificate"],"content":"빅데이터 분석기사.\n요즘 IT 업계에서 가장 뜨거운 자격증 중 하나면서 금융권 개발을 하기에 필수적인 내용이기에 호기롭게 도전장을 내밀었다.\n데이터에 관심도 있고, 프로그래밍 기초도 있으니 어렵지 않겠지’라는 안일한 생각으로 시작했던 공부가 이렇게 나를 놀라게 할 줄은 몰랐다.\n처음에는 파이썬이나 R 같은 프로그래밍 언어로 데이터를 다루는 실습 위주일 거라 예상했다.\n하지만 실제 교재를 펼치고 보니 이론적 배경과 개념, 법과 제도까지 폭넓게 다루고 있어 당황스러웠다.\n‘이 모든 것을 다 알아야 하나?‘라는 의문이 들며 부담감이 밀려왔다.\n\n지금까지 내가 공부하고 이해한 내용은 이렇다.\n빅데이터 개요 및 활용: 빅데이터의 정의부터 시작해 특성(3V/4V/5V), 데이터의 유형, 빅데이터 활용 사례까지.\n단순히 ‘큰 데이터’가 아니라 그 특성과 가치에 대해 배웠다.\n빅데이터 기술 및 제도: 이 부분에서 첫 번째 큰 벽을 만났다. 빅데이터 관련 법과 제도라니…\n개인정보보호법, 정보통신망법, 신용정보법 등 다양한 법과 제도를 이해해야 했다. 기술적인 내용은 하나하나 이해하며 지나가면 되는데, 암기 위주의 법률적 내용은 정말 쥐약이였다.\n빅데이터 분석 계획: 분석 목표 설정부터 데이터 수집 계획, 품질 관리 방안까지.\n‘좋은 데이터’가 무엇인지, 어떻게 데이터의 품질을 보장할 수 있는지에 대한 내용들이 주로 기억에 난다.\n분석 방안 수립: 다양한 분석 기법과 알고리즘의 개요를 배웠다.\n아직 깊이 있게 다루진 않았지만, 앞으로 배울 내용의 방대함을 예감할 수 있었다. 회귀분석, 분류분석, 군집분석 등 용어만 들어도 심장이 쿵쿵 뛴다.\n분석 작업 계획: 프로젝트 관리의 관점에서 분석 작업을 어떻게 계획하고 관리할 것인지에 대한 내용.\n일정 관리, 자원 배분, 위험 관리 등 프로젝트 매니지먼트 요소가 많이 들어있어 의외였다.\n\n정말 예상치 못했던 부분은\n이론적 배경의 방대함이다.\n단순히 도구를 사용하는 법을 배우는 것이 아니라, 통계학, 컴퓨터 과학, 데이터베이스 이론 등 다양한 학문 분야의 지식이 필요하다는 점이 부담으로 다가온다.\n빅데이터 플랫폼들과 아키텍처에 대한 내용도 생소했다.\n하둡, 스파크, NoSQL 등의 개념을 이해하는 것 자체가 쉽지 않다.\n이런 기술적 배경 지식이 왜 필요한지는 이해하지만, 실제로 모든 내용을 습득하는 것은 쉽지 않을 것 같다.\n\n그래서 솔직히 말하면,\n시작한 지 몇일 되지않아 벽을 느끼고 있다.\n이렇게 방대한 내용을 모두 공부해야 한다는 생각에 부담감이 크다.\n하지만 동시에, 빅데이터가 단순한 기술이 아니라 사회적, 법적, 윤리적 측면까지 고려해야 하는 복합적인 분야라는 것을 알게 된 것은 의미 있는 발견이었다.\n아직 시작에 불과하지만, 하루하루 조금씩 앞으로 나아가려 한다.\n처음부터 모든 것을 완벽하게 이해하려 하기보다는, 전체적인 흐름을 파악하고 점차 깊이를 더해가는 방식으로 접근해야겠다는 생각이 든다.\n빅데이터 분석기사는 단순한 자격증이 아니라 데이터를 바라보는 통합적인 시각을 기르는 과정이라고 생각하면 조금 더 의미가 있을 것 같다.\n\n어떻게 나아갈것이냐..\n우선 스터디의 학습계획에 최대한 맞춘다.\n내 학습속도랑 비교했을때 우리 빅분기 스터디에서 정한 양은 꽤 많은 것 같다.\n그치만 나를 죽이지 못하는 고통은 나를 성장하게 한다하지 않는가..\n되든 안되든 할수있는 최대한 이겨내고 2회독을 돌린다면 전공생급의 이론 지식을 가질것이다.\n학습 속도를 올릴 최적의 시간표를 짜야한다.\n사실 그 동안은 어느정도 여유로운 일정이여서 내 개인 공부를 하며, 그동안 부족했던 CS지식들을 채워나갔다.\n그러면서 회고록을 작성하는데 공부하는시간까지 포함하면 4~5시간이 걸릴때도 있고,\n그 조차 몇 회차로 회고를 나누거나, 그냥 내용을 끊어버리는 경우도 있었다.\n이제는시간을 가장 효율적으로 사용을 해야 할 때이고 선택과 집중을 해야 할 때가 된 것 같다. // 생각보다 빠르게 이 시기가 와버렸다..\n하지만 분석기법들은 깊이있게 공부하자.\n항상 이런 기법들에 대해서 이론적으로 알고가면 변칙적인 문제에 맨날 털린다.\n적어도 개발 자격증에서는 기법이나 코드, 언어가 나온다면 직접 코드를 쳐볼뿐만 아니라,\n거시적인 배경을 파악을 하고, 또 꼬리질문을 통해 미시적인 분야까지 통달을 해야 한다고 생각한다.\n\n당장은 어렵고 방대하게 느껴지지만,\n한 번에 다 이해하려 하지 말고 점진적으로 접근해보려 한다.\n빅데이터의 세계는 생각보다 훨씬 넓고 깊다. 쉽지는 않겠지만, 한 걸음 한 걸음 나아가다 보면 어느새 성장해 있지 않을까?\n현재 느껴지는 나에 대한 의구심은 아마도 모든 배움의 과정에서 겪는 자연스러운 단계일 것이다.\n지금은 모든 것이 어렵고 복잡하게 느껴지지만, 성장을 하려면 스트레스가 동반 되어야한다라고 생각하면 조금 위안이 된다.\n끝까지 포기하지 말고 성공하는 습관을 들여가자."},"diary/plans-for-study":{"slug":"diary/plans-for-study","filePath":"diary/plans-for-study.md","title":"앞으로의 계획","links":[],"tags":["Dev"],"content":"인재 개발원에 온지 한달차..\n이제 학원 오기 전, 궁금했던 기술들을 어느 정도 정리가 되었다.\n회고 형식으로 하나씩 블로그에 풀어보기도 했고,\n내가 몰랐던 개념들이 어떻게 이어지는지 구조적으로 이해하려고 노력했다.\n이렇게 글도 작성하고, 프로젝트도 짧게 해보면서\n이제는 나도 모르게 2년차의 짬이라는 게 조금은 생긴 것 같다는 생각이 들었다.\n그치만 이럴때 자만하지말자…\n그래서 오늘은 내가 뭐가 부족한지, 어떤 기술들을 더 공부해야 하는지를\n조금 더 깊이 있게 탐색하는 시간을 가져보았다.\n\n사실 이 작업을 시작하기 전까지만 해도\n“많이 없겠지. 이제 웬만한 건 알잖아” 라는 생각이었는데…\n마인드맵을 정리해보니까 생각보다 엄청 많더라.\n스마트 인재개발원 끝날 때까지 회고 열심히 써도 다 이해 못하고 끝날 수도 있을듯…\n그렇기에 이 내용들을 무턱대고 다 공부하겠다는 생각은 버리고\n중요도랑 우선순위를 나눠서 하나씩 천천히, 꾸준히 해보려고 한다.\n\n마무리…\n이번 회고를 통해 내가 어디쯤 서 있는지, 그리고 어디로 나아가야 하는지를 조금 더 선명하게 볼 수 있었다.\n그리고 이 모든 과정을 통해 내가 만든 서비스를, 내가 스스로 설명하고 책임질 수 있는 사람이 되는 것.\n그게 지금 내가 목표로 삼고 있는 방향이다.\n\n추가적으로…\n이번에 마인드맵 정리를 하면서 쓴\ncoggle.it/이라는 서비스가 생각보다 너무 마음에 들었다.\n생각을 정리하는 데도 도움이 되고,\n무엇보다 내가 뭘 알고 있고 뭘 모르는지 한눈에 파악하기가 정말 좋았다.\n이번엔 내가 모르는 것들만 따로 정리했지만,\n다음엔 내가 어디까지 알고 있고, 어디로 나아갈 건지 전체 맥락까지 다뤄보는 걸 해볼 생각이다.\n기술도, 방향도, 흐름도 다시 한번 재정비할 타이밍이다."},"etc/jwt":{"slug":"etc/jwt","filePath":"etc/jwt.md","title":"웹 보안과 JWT","links":[],"tags":["Dev","Backend","Frontend","JWT","web-security"],"content":"먼저 웹 보안이 뭘까요?\n웹 보안은 웹 사이트나 웹 관련 서비스를 외부의 악의적인 공격이나 무단 접근으로부터 보호하기 위한 기술적, 관리적, 물리적 조치를 의미합니다.\n저희 웹개발자는 물론 다른 부분도 신경을 써야하지만 주로 보안 취약점을 미리 발견하고 개선하여 사용자들이 문제없이 서비스를 사용할 수 있도록 개발을 해야합니다.\n\n그러면 보안은 어떤게 있을까?\n웹 보안은 여러 계층으로 나뉘는데, 방화벽이나 침입 탐지 시스템와 같은 네트워크 보안 단계부터 해서 서버 및 애플케이션 보안, 그리고 인증 및 인가 등이 있습니다.\n우리가 오늘 알아 볼 부분은 가장 쉽게 구현이 가능하면서도, 아주 강력한 인증과 인가 기술와 이를 기반으로 한 JWT에 대해서 살펴보도록 하겠습니다.\n\n인증과 인가\n웹 보안의 핵심 요소 중 하나인 인증( authentication )은 사용자가 실제로 본인이 주장하는 사람인지를 확인하는 과정을 의미합니다.\r\n일반적으로 로그인을 하는 과정을 인증이라고 합니다. 서비스에 들어가기 위해서 해당 유저인지 인증을 받는것이죠.\n반면에 인가( authorization )는 인증을 거친 사용자가 웹 서비스 내에서 특정 페이지나 리소스, 기능 등 에 접근할 수 있는 권한을 부여하는 것을 의미합니다.\n인증을 통해 로그인한 사용자에게 여러 페이지나 데이터를 제공하도록 인가를 해주는거죠. 이를 통해서 웹 주소만을 가지고 중간 페이지에 접속한다거나, 데이터를 빼가는 문제를 차단해줍니다.\n인증과 인가의 영단어가 많이 헷갈릴 수 있는데, 서비스에 인증하려할때 어델!! → 어델!!티케이션..과 어서와~ → 어서와이제이션.. 이라고합니다. 너무 킹받아서 바로 외워졌던…\n\n인가를 대표하는 JWT\n기존에는 인가를 처리하려면 세션 저장 방식을 사용을 해야했습니다.\n세션 저장 방식이란, 유저가 인증을 받게 되면 입장권을 반으로 찢어서 유저가 절반을 가져가고 서버가 나머지 절반을 나눠가지면서 인가가 필요할때마다 서로 대조를 하면서 확인을 하는 방식입니다.\n\n세션은 여러가지 문제점을 가지고 있는데, 아래와 같은 크리티컬한 문제를 가지고 있습니다.\n\n서버에 대해서 업무가 과중 될 수 있습니다. 서비스가 인가를 처리하는 프로세스는 하나인데, 수 만명이 몰리게 되면 병목 현상이 생기거나 에러가 발생할 수 있습니다.\n보통 절반의 입장권은 웹에서 저장을 하기 때문에, 위와 같은 에러가 발생하게되면 데이터가 초기화 되면서 유저나 서버가 저장하고 있던 입장권이 날아갈 수 있습니다.\nMSA와 같이 다중 서버로 운영되는 서비스라면 각각의 서버마다 입장권을 복사해서 관리해야 하는 문제가 발생합니다. 이러한 중복 데이터는 서버 간 데이터 동기화 문제를 일으키고, 데이터 관리 비용을 증가시키는 단점으로 작용하게 됩니다.\n\n\n이러한 세션의 문제들을 해결하기 위해서 등장한 것이 JWT입니다. JWT는 서버에서 별도의 세션을 유지하지 않아도, 토큰 자체에 사용자 정보와 권한 데이터를 포함하고 있습니다.\n그 말인 즉슨, 인증과 인가가 된 유저 정보가 들어있는 토큰만 들고다닌다면 서버는 단순한 검증만 하면 되기 때문에 자유롭게 서비스가 이용 가능하다는 뜻이죠.\n\n토큰은 어떻게 구성이 되어있을까?\n토큰은 JWT.io 사이트에 들어가면 어떻게 생성이 되는지 알 수 있습니다.\n이 사이트에서 제공하는 예시 토큰을 통해서 토큰의 구성을 알아 보도록 하겠습니다.\n\n이미지의 왼쪽을 보면 유저가 실제로 가지고 다니는 인코딩되어있는 토큰 형태를 알 수 있습니다.\n토큰은 . 을 통해서 3가지 분류로 나눠져 있는데요, 무슨 뜻인지 알려고 한다면 오른쪽과 같이 디코딩을 통해서 값을 확인 할 수 있습니다.\n디코딩을 하고나니 3가지의 JSON 형태의 데이터를 확인 할 수 있는데요. // JWT, Json Web Token인 이유..\nHeader, Payload, Signature으로 구분이 됩니다.\n\n그럼 각각의 의미를 한번 알아볼께요\nHeader에는 alg와 typ이 있습니다.\ntyp은 JWT라고 되어있는데 JWT의 토큰이라는것을 명시해줍니다.\nalg는 알고리즘을 의미하며, HS256이나 RS256등 토큰을 암호화할때 필요한 알고리즘이 명시 되어 있습니다.\nPayload에서는 다양한 유저의 정보를 확인 할 수 있습니다.\n유저의 정보, 토큰의 만료시간, 발급자 등 을 통해서 사용자의 신원과 권한을 확인 할 수 있습니다.\nSignature은 헤더와 페이로드를 조합하여 생성된 암호화된 문자열입니다.\n서명이 중요한 이유는, 토큰을 발급할 당시의 정보를 가지고 알고리즘을 통해 토큰화를 한거기 때문에, 토큰 발급 이후에 header나 payload 값이 변경이 되면 서명의 값이랑 일치하지 않아 기존의 정보가 변조되지 않았음을 검증할 수 있는 데이터입니다.\n\nex) 초기 데이터 : HS256 + 옥진석 = abcd → Payload 탈취 후 수정 : HS256 + 진석옥 = dcba\n→ 기존의 Header : HS256, Payload : 옥진석, Signature : abcd랑 다르기 때문에 인가되지 않음\n그러면 JWT는 완벽한 보안 방식이 아닌가?\n\n그렇다면 JWT는 완벽한 보안 도구이지 않는가?\n여느 보안 도구들과 마찬가지로 JWT도 단점이 존재하기는 합니다.\n가장 치명적인 단점이 토큰이라는 입장권은 서버에서 관리하는게 아니라 유저의 손에 쥐어주는것이기 때문에, 문제가 발생했을때 토큰을 강제로 만료시키거나 폐기하는 것이 쉽지 않습니다.\n나중에 특정 문제로 인해 서비스의 인가 등급이 변경 되더라도, 이미 인가가 되어버린 토큰을 계속해서 활용해서 활동이 가능하다는 뜻이죠.\n위와 같은 문제를 보완하기 위해 Access Token과 Refresh Token 개념이 도입되었습니다.\nAccess Token은 짧은 유효 기간을 가지고 있어서 탈취되더라도 빠르게 만료되어 서버의 개입 없이도 서비스 사용이 제한됩니다.\n근데 그러면 짧은 Access Token 때문에 사용자가 다시 로그인을 해야 한다면 상당히 불편하겠죠?\n이 문제를 해결하기 위해 Refresh Token이 도입되었습니다.\nRefresh Token은 더 긴 유효 기간을 가지며, Access Token이 만료되었을 때 새로운 Access Token을 발급받는 데 사용됩니다.\n사용자가 서버에 새 토큰을 요청하면, 서버는 Refresh Token의 유효성을 확인한 후 새로운 Access Token을 발급합니다.\n이렇게 하면 사용자는 자주 로그인할 필요 없이 서비스를 이용할 수 있으면서도, 기존의 JWT 문제를 보완한 서비스가 완성됩니다.\n\n마무리…\n여기까지 봤을 때 JWT는 인증과 인가에 대해서 완벽해 보이지 않나요?\n하지만 여전히 보안은 끝이없는 창과 방패의 싸움입니다. 누군가는 이런 보안체계를 뚫고 문제를 일으키려 할껍니다.\n최근에는 JWT만으로는 부족한 상황에서 MFA라고 하는 다중 인증기술이나 메일로 2차 인증을 하게 하는 OTP와 같은 추가적인 보안 계층을 도입하는 추세입니다.\n이러한 방식은 “내가 알고 있는 것”(비밀번호), “내가 가지고 있는 것”(휴대폰이나 보안 토큰), “내가 그 자체인 것”(지문이나 얼굴 인식)과 같은 여러 요소를 조합하여 보안을 강화합니다.\n결국 돌아보면 완벽한 보안 솔루션은 존재하지 않습니다.\n우리 개발자들은 항상 최신 보안 동향을 파악하고, 다양한 보안 계층을 적절히 조합하여 사용자의 데이터와 서비스를 보호해야 합니다.\nJWT는 이 과정에서 단 하나 기술일 뿐, 보안의 전부가 아니라는 점을 기억해야 합니다.\n웹 개발에서 보안은 선택이 아닌 필수입니다. 여러분의 서비스가 사용자에게 신뢰와 안전을 제공할 수 있도록, 보안에 대한 관심과 학습을 멈추지 마시길 바랍니다!"},"etc/protocol":{"slug":"etc/protocol","filePath":"etc/protocol.md","title":"프로토콜에 대한 고찰","links":[],"tags":["Dev","Backend","Frontend"],"content":"아침 출근길,\n유튜브를 보다가 내 알고리즘을 타고 온 RESTful API에 관한 짧은 영상을 보게 되었다.\n처음에는 단순히 RESTful API에 대해 아직 잘 모르기 때문에 이해하려는 목적이었지만, 해당 영상이 이론에 대해서 너무나 쉽고 재미있게 설명을 해서 RESTful API뿐만 아니라 시리즈로 구성이 되어있던 SOAP, GraphQL, gRPC를 소개하는 영상까지 시청을 하였고, 나는 이들이 프로토콜이라는 이름으로 불린다는것을 알게 되었다.\n순간 “이제야 이걸 알게 되다니?” 라는 부끄러움과 동시에 과거 공부했던 프로토콜이란 단어가 떠올랐다.\r\n그때 당시에는 프로토콜이란 단어 자체가 너무 딱딱해서 이거를 어떻게 이해해..? 하면서 거부감이 생겼었는데, 막상 영상을 보면서 하나하나 까보니 다 한번쯤은 사용해봤거나 어디선가 들어본 내용들이여서 오히려 친숙하게 느껴졌다.\n\n그러면 이해하게 된 프로토콜이란 뭔데?\n프로토콜은 컴퓨터 네트워크에서 데이터를 주고받을 때 사용하는 규칙과 약속의 집합이다.\r\n사람들이 언어를 통해 의사소통하듯이, 네트워크 상의 시스템도 특정한 규칙을 따라야 서로 원활하게 통신할 수 있다.\nAPI에서의 프로토콜은 클라이언트와 서버 간의 통신 방식을 정의하는 규칙이며, 특정한 데이터 형식과 요청 방식, 응답 처리 방식 등을 정리한 것이다.\n\n1. RESTful API\nRESTful API는 현시점 개발자가 가장 많이 접하는 API 방식 중 하나일것이다. 나 또한 개발 프로젝트를 6번을 접했지만 4번은 RESTful API로 개발을 한 경험이 있다.\r\n이처럼 우리가 만들 서비스에서 데이터를 주고받을 수 있는 가장 기본적인 방법 중 하나이다.\n왜 RESTful API가 가장 일반적인 방법 중의 하나일까?\r\nRESTful API는 JSON이라는 포맷 형식으로 데이터를 주고받는다.\n// JSON 형식\n{\n  &quot;id&quot;: 1,\n  &quot;name&quot;: &quot;Alice&quot;,\n  &quot;email&quot;: &quot;alice@example.com&quot;\n}\n누가봐도 이해하기 쉽지 않은가? 그렇기에 어떤 개발자든 쉽게 데이터를 운용할 수 있다는 장점이 있고,\n또한 이해하기 쉬운 URL과 SQL의 DML 구문처럼 CRUD ( Create, Read, Update, Delete )를 바탕으로 요청을 보내고 받기 때문에 학습량이 적다는 장점이 있다.\n\n예시\napi.example.com/**/users**/1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n동작HTTP 메서드API URL 형식설명Create (생성)POST/users새로운 사용자 생성Read (조회)GET/users모든 사용자 목록 조회Read (조회 - 특정 데이터)GET/users/{id}특정 사용자의 정보 조회Update (수정)PUT / PATCH/users/{id}특정 사용자 정보 수정Delete (삭제)DELETE/users/{id}특정 사용자 삭제\n\n🎥 얄코의 RESTful API 강의\n\n\n2. SOAP (Simple Object Access Protocol)\nSOAP는 보안과 데이터 무결성이 중요한 시스템에서 사용하는 API 방식이다.\r\n특징으로는 보안이 매우 뛰어나 중요한 정보를 운용하는 환경에서 널리 사용된다고 한다.\nSOAP은 어떻게 데이터를 보내고 받길래 보안에 용이할까?\r\n바로 XML이라는 복잡한 방식을 통해 데이터 구조를 엄격하게 정의할 수 있기에 정합성과 보안성이 타 형식보다 높다고 볼 수 있다.\n&lt;response&gt;\n  &lt;user&gt;\n    &lt;id&gt;1&lt;/id&gt;\n    &lt;name&gt;Alice&lt;/name&gt;\n    &lt;email&gt;alice@example.com&lt;/email&gt;\n  &lt;/user&gt;\n&lt;/response&gt;\n\n또한 다른 프로토콜과 다르게 캐싱에도 강점이 있는데,\n바로 API들끼리 유기적으로 동작을 할때, 서버에서 데이터를 캐싱할 수 있어서 트랜잭션 동작을 수행을 지원해준다는 것이다. 이를 통해서 다른 프로토콜에서는 하기 어려운 방식으로 데이터 정합성을 유지하는 데 강점이 있다.\n마지막으로 WS-Security 같은 강력한 보안 메커니즘을 지원해주는데 이는 XML 디지털 서명, XML 암호화, 보안 토큰 등을 사용하여 메시지의 무결성과 기밀성을 보호해주기 때문에 IBM과 같은 기업에서 보안성을 높이기 위해 많이 사용된다고 한다.\n하지만, 무거운 XML 구조로 인해 속도가 느릴 수 있다는 단점이 있으며, RESTful API 처럼 직관적인 접근 방식이 아니기 때문에 사람을 대상으로 사용하기 보다는 컴퓨터나 프로그램을 대상으로 많이 사용한다고 한다.\n\n🎥 얄코의 SOAP 강의\n\n\n3. GraphQL\nGraphQL은 최근 공고를 보면 굉장히 많은 기업에서 해당 기술의 역량을 요구하는 것을 확인 할 수 있었다.\n이 기술을 볼때마다 저건 무슨 SQL일까..? 라며 아무 생각없이 그냥 지나쳤는데.. ㅎㅎ\n암튼, 왜 GraphQL이 요즘 많이 활용이 되고있는지, 어떻게 사용할 수 있는지도 한번 알아보자.\nGraphQL은 클라이언트가 원하는 데이터만 선택적으로 요청할 수 있는 API 방식이다.\r\nRESTful API가 미리 정해진 JSON형식의 데이터 구조를 반환하는 반면, GraphQL은 필요한 데이터만 요청하고 받아서 네트워크 성능 최적화가 가능하다는 장점이 있다.\n즉, Overfetching을 방지하여 성능을 높일 수 있다는 강점이 있는것이다.\r\n최근 기업들이 비용 절감과 필요 기능만을 구현하는 오픈 소스에 열광하는 흐름과도 비슷한 맥락으로 볼 수 있을 것이다.\nGraphQL의 가장 큰 특징 중 하나는 쿼리 언어를 기반으로 한다는 점이다.\n그렇기 때문에 DB와 같이 스키마를 작성하는 점이 아주 특이했다.\ntype User {\n  id: ID!\n  name: String!\n  email: String!\n  posts: [Post]\n}\n \ntype Post {\n  id: ID!\n  title: String!\n  content: String!\n  comments: [Comment]\n}\n \ntype Comment {\n  id: ID!\n  content: String!\n  author: User\n}\n\n위와 같은 스키마를 설정하면, 해당 구조를 기반으로 요청을 보낼 수 있다.\n// request\n{\n  user(id: 1) {\n    name\n    email\n    posts {\n      title\n      comments {\n        content\n        author {\n          name\n        }\n      }\n    }\n  }\n}\n \n// response\n{\n  &quot;user&quot;: {\n    &quot;name&quot;: &quot;Alice&quot;,\n    &quot;email&quot;: &quot;alice@example.com&quot;,\n    &quot;posts&quot;: [\n      {\n        &quot;title&quot;: &quot;GraphQL의 장점&quot;,\n        &quot;comments&quot;: [\n          {\n            &quot;content&quot;: &quot;좋은 글이네요!&quot;,\n            &quot;author&quot;: {\n              &quot;name&quot;: &quot;Bob&quot;\n            }\n          }\n        ]\n      }\n    ]\n  }\n}\n그러면 이제 해당 스키마를 바탕으로 어떻게 코드를 작성해야 하는가?\n해당 유튜브의 내용에 따르면 개발 환경에 따라서 많이 달라지는것 같다.\r\n나중에 GraphQL을 사용할 수 있는 프로젝트를 기획해서 한번 사용을 해봐야 알 것 같다.\n아래는 GraphQL 문법을 조금 더 쉽게 사용하도록 도와주는 커뮤니티 링크이다.\r\n직접 만들기보다는 tailwind처럼 복사해서 사용하는 경우도 많은가보다.\n\nGraphQL 활용 사이트\n\n\nAPI의 요청과 응답에 관해서는,\nRESTful API에서는 /users/1, /users/1/posts, /users/1/posts/{postId}/comments 등 여러 개의 API 요청을 보내야 하지만,\r\nGraphQL에서는 한 번의 요청으로 사용자의 기본 정보, 작성한 게시글, 해당 게시글의 댓글 및 작성자 정보까지 한꺼번에 받을 수 있다.\n이처럼 GraphQL은 원하는 데이터만 선택해서 받을 수 있도록 해주며, RESTful API의 단점인 불필요한 데이터 요청과 응답을 줄이는 것에 최적화되어 있다.\r\n하지만 클라이언트가 너무 많은 데이터를 한 번에 요청할 경우 서버 부담이 증가할 수 있으므로, 적절한 요청 설계가 필요하다.\n\n🎥 얄코의 GraphQL 강의\n\n\n\n\n이런식으로 프로토콜을 한번 정리하고 나니, 마치 작은 퍼즐 조각들이 하나 둘 맞춰지는 기분이었다.\n아침부터 깨달음에 대한 도파민으로 현자와 같은 표정으로 출근을 했다.\n그러나 곧 한 퍼즐조각이 없다는걸 깨닫게 되었다..\n\n\n그때 사용했던 API는 무엇이었을까?\n나는 1년 전에 JSP를 이용해서 API를 만들었던 경험이 있었다.\r\n그런데 이상했다. 당시 API는 JSON을 반환하지도 않았고, XML은 더더욱 아니었다. 그렇다면 내가 만든 API는 대체 어떤 방식이었을까?\n이 궁금증을 해결하기 위해 G 선생과 대화를하며 심도 깊은 내용을 주고 받았다.\n\n내가 궁금했던 점\n\nJSP는 어떤 방식의 프로토콜을 통해 데이터를 받아오는가?\nHTTP API는 어떻게 데이터 HTML 형식을 주는가?\nHTTP의 장단점은 무엇인가?\n\n\nJSP는 어떻게 동작할까?\nJava Server Pages는 기본적으로 백엔드 서버에서 HTML을 동적으로 생성하여 반환하는 방식을 사용한다.\n예를 들어, 사용자의 로그인 정보를 데이터베이스에서 가져와 HTML 코드 내에 삽입하고, 이렇게 생성된 HTML을 클라이언트( =웹 브라우저 )에게 전달하면, 브라우저는 이를 웹페이지로 렌더링한다.\n이 방식에서는 백엔드 서버가 직접 웹페이지를 구성하며, 클라이언트는 단순히 해당 HTML을 표시하는 역할만 수행한다. 즉, JSP는 클라이언트가 데이터를 직접 가공하여 활용하기보다는, 완성된 화면을 받아 그대로 출력하는 구조라고 볼 수 있다.\n\nJSP가 HTML을 반환할 수 있는 이유\nJSP가 HTML을 반환할 수 있는 것은 HTTP의 동작 방식과 HTTP API의 특징 때문이다. HTTP는 단순히 데이터를 주고받는 전송 프로토콜이며, 서버가 어떤 형태의 데이터를 반환할지는 HTTP의 Content-Type 헤더에 따라 결정된다.\n일반적으로 API는 JSON이나 XML을 반환한다고 생각할 수 있지만, 사실 HTTP API는 다음과 같은 다양한 형식의 데이터를 반환할 수 있다.\n\nHTTP API가 반환할 수 있는 데이터 형식\n\nHTML (Content-Type: text/html)\nJSON (Content-Type: application/json)\nXML (Content-Type: application/xml)\n파일 (이미지, PDF 등) (Content-Type: application/pdf 등)\n단순 텍스트 (Content-Type: text/plain)\n리디렉션 (HTTP 301 Moved Permanently, HTTP 302 Found)\n\n\n즉, HTTP API는 특정한 데이터 형식에 제한되지 않으며, 서버가 어떤 형식을 반환하느냐에 따라 클라이언트의 동작 방식도 달라진다. → 서버사이드 렌더링, SSR의 개념이다.\n그렇다면 HTTP API방식은 RESTful의 API나 SOAP의 장점들을 다 사용할 수 있다는것 아닌가..?\n바로 보안과 유지보수에 필요한 작업 효율성이 중요한 금융권이 생각이 났다.\n여태까지 금융권은 왜 이러한 레거시 시스템을 사용을 하면서 사람들의 불편함을 감내할까? 이런 생각을 자주 했었는데, 금융 시스템은 다양한 포맷을 다루는 일이 많고 또 안전하기까지하니 적절한 대체 방안이 없지않았나 하며 금융권을 조금 더 이해 할 수 있었다.\n\n\n마무리…\n이번 회고를 통해서 단순히 기술을 비교하고 이해하는 것뿐만 아니라, 과거에 이해하지 못했던 기술적인 선택들이 왜 이루어졌는지 깊이 고민해볼 수 있었다.\r\n처음에는 단순히 ‘왜 금융권은 이런 방식을 고수하는 걸까?‘라는 궁금증에서 시작했지만, 다양한 프로토콜을 분석하면서 당시의 환경과 요구사항 속에서 가장 효율적인 선택을 한 것임을 이해하고 공감할 수 있었다.\nRESTful API, GraphQL, gRPC 등 최신 기술들이 더 편리하고 효율적이라고 하지만, 결국 중요한 것은 도메인에 적합한 기술을 선택하는 것이다.\r\n금융권이 HTTP API와 JSP를 유지했던 이유도, 단순히 보수적이어서가 아니라 보안성, 데이터 정합성, 다양한 형식의 데이터 처리 등 실질적인 요구사항을 만족시킬 수 있었기 때문이다.\n이제 앞으로 기술이 변화하고 마이그레이션이 진행되더라도, 단순히 새로운 기술을 도입하는 것이 중요한 것이 아니라, 어떤 부분을 중점적으로 고려해야 하는지에 대한 인사이트를 가지게 되었다.\r\n기술을 선택할 때는 그저 유행을 좇는 것이 아니라, 요구사항과 기술적 타당성을 기반으로 한 최적의 해결책을 찾아야 한다는 점이 더욱 중요함을 깨달았다.\n아침 출근길, 유튜브에서 시작된 작은 호기심이 예상보다 깊은 고민으로 이어졌다.\r\n그리고 나는 오늘, 단순히 새로운 기술을 배우는 것이 아니라, 기술을 바라보는 시각 자체를 성장시킬 수 있었다.\r\n앞으로도 이런 과정을 반복하며, 단순히 ‘잘 쓰는’ 개발자가 아닌, ‘왜 사용하는지 이해하고 선택할 줄 아는’ 개발자가 되어야겠다고 다짐하게 되었다."},"etc/whit-is-mcp":{"slug":"etc/whit-is-mcp","filePath":"etc/whit-is-mcp.md","title":"MCP...?","links":["(https:/docs.anthropic.com/ko/docs/agents-and-tools/mcp)"],"tags":["Dev","AI","에이전트","LLM"],"content":"요즘 내 알고리즘에는..\n**Model Context Protocol( MCP )**라고 하는 기술로 도배되어있다.\n이게 내 알고리즘에 뜨는이유가 처음에는 정말 의아했다.\nMCP가 관심이 있었는가? 아니요..\nMCP를 알고는 있는가? 아니요..\n아 있었는데..?? 아뇨 없어요..\n그런데 왜.. 추천이 뜨는거지?? 하고\n썸네일이 재미있어보이는 영상을 한번 들어가봤는데 정말 충격 그 자체였고,\n짤막한 영상에서도 왜 내 알고리즘이 MCP로 핫한지 바로 알 수 있었다.\n\n\n  \n    \n  \n  \n    \n  \n\n이게.. 보이는 그대로다.\n유저가 요청을 하면 LLM이 마인크래프트와 연동하여 자기 스스로 동작을한다..\n처음에는 마인크래프트가 앤트로픽이랑 프로젝트를 하나 한건가..?\n아니면 또 AI로 게임을 만들라했는데 마인크래프트 수준으로 만든건가..? 라고 생각을했다.\n아무리 생각해도 스스로 돌아가는 것은 말이 안된다고 생각했기 때문이다.\n그런데 실제로 그렇다고 한다..\n\nAnthropic 공식 문서를 보면\n\nMCP는 애플리케이션이 LLM에 컨텍스트를 제공하는 방식을 표준화하는 개방형 프로토콜입니다.\nMCP를 AI 애플리케이션의 USB-C 포트라고 생각하세요. USB-C가 다양한 주변 기기 및 액세서리에 장치를 연결하는 표준화된 방식을 제공하는 것처럼 MCP는….\n\n정리해 보면 MCP는 다른 서비스들이 C-Type 형식으로만 제공해주면 얼마든지 사용을 할 수 있고,\n아마 말하는 C-Type은 프로토콜 특성 상 API와 Json인듯 하다.\n즉, API만 제공이 된다면 얼마든지 AI를 활용해서 자동화가 가능하다…?\n\n\n정말 개발자로서 숭한 것이 나온 듯 하면서도..\n무궁무진한 서비스들과의 연결이 될까..?\n아니면 MCP 활용이 과열되면서 또 API를 제공하는 회사들이 비용을 무지막지하게 올려버리는거 아닌가..? 하는 생각이 들면서\n결과적으로는 MCP를 위한 서비스가 또 나와야 하는구나 하는 스스로의 결론에 도달했다.\n그러나 확실한건 지금 사용해보기에 너무나도 신기하고 재미있는 기술인거다.\n그 이후로 저 마인크래프트 영상 뿐만아니라 다양한 서비스를 만드는 것들을 찾아 봤는데,\n거의 아메리카의 서부시대마냥..\n엄청나게 많은 사람들이 깃발을 꽂아가며 서비스를 생산해내고 있었다.\n\n나도 아이디어 노트에 하나씩 끄적여보고있는데,\n아직은 MCP를 이해를 제대로 못한건지 아니면 기존의 서비스라는 것에 대한 관성인건지\n기존의 아키텍쳐를 도려내고 그 부분을 대체하는것이 쉽지가 않다.\n어느정도 정리가된다면 중간 프로젝트든 파이널 프로젝트든 한번 도입을 할 수 있는 기회가 되면 좋겠다.\n\n마무리…\nMCP를 공부하면서 아래 영상이 굉장히 인상깊었다.\n\n이 분은 LangChain과 LangGraph라는 기술을 MCP와 연결한 서비스를 만들어 보았다고 한다.\n짧게 나온 이론을 보면 LangChain은 이름 그대로 여러 단계를 체인저럼 이어서 LLM을 활용 할 수 있게 해주는건데\nLLM 호출은 기본이고 프롬프트 템플릿, 문서 검색, DB 검색과 같은 기능들까지 체인에 포함 할 수 있다라는 거고,\n서비스에서 GPT가 명확하게 뭘 할지 사람이 정해준다는 것이다.\n그리고 LangGraph는 LangChain을 보완하기 위해서 나온 프레임 워크라고 한다.\nLangChain은 대화가 길어질수록 상태를 추적하기 어렵고, 사용자의 입력에 따라 흐름이 바뀌는것또한 경직되어있다는 단점을 가지고 있었는데,\n이러한 단점을 LangGraph가 노드를 활용해서 상태를 추적하며 보완을 해준다는 것이다.\n정리해보면 이 유튜버는\nMCP 또한 LangChain처럼 상태 추적이나 유연한 대화를 못하니까,\n이를 보완하기 위해서 LangChain과 LangGraph를 연결한 듯 한데\n서비스 기획을 하고싶은 내 입장에서는 더 어려워졌다.\n아직은 가가 가가…? (그 아이가 그 아이니..?) 상태다.\n이러한 존재들을 에이전트라고 하는 듯 하는데,\n내일 한번 싹 정리해서 공부를 하고 시리즈로 게시글을 작성해봐야겠다."},"index":{"slug":"index","filePath":"index.md","title":"Inside Jinseok","links":[],"tags":["Dev","Portfolio","Backend","Frontend","Database","Data-Analytics","AI","Fintech"],"content":"저는 이런사람입니다.\n[ 문제 해결을 즐기고, 고민하기를 좋아하는 개발자 ]  \n어떤 문제든 다양한 시도와 깊이 있는 고민을 통해 제 것으로 만들 때 진정한 성취감을 느낍니다.\n이러한 경험은 앞으로 실패를 마주하더라도, 스스로를 믿고 다시 일어설 수 있는 힘이 된다고 생각합니다.\n[ 개발 규칙을 지키는 것을 좋아하며, 하나의 팀으로 협업하는 개발자 ]  \n프로젝트 환경과 팀의 특색에 맞는 개발 문화를 만들어나가고, 하나의 목표를 향해 효율적으로 나아가는 것을 지향합니다.  \n[ 금융 시장의 트렌드를 주시하며, 핀테크와 관련된 스킬을 꾸준히 학습하는 개발자 ]  \n학부 시절부터 쌓아온 금융 지식을 다양한 프로젝트에 접목해 실질적인 문제를 해결 할 수 있는 개발자로 성장하고 있습니다. 더불어 금융 개발자라는 목표를 가지고 앞으로의 성장 방향을 계획해 나아가고 있습니다.\n\n서비스를 개발할 때…\n단순히 기능을 구현하는 것만으로는 충분하지 않다고 생각합니다.  \n기술을 적용할 때에 기반이 되는 원리를 이해하고, 기술이 서비스에 어떻게 적용될 수 있는지 고민하는 과정이 필요합니다. 기능을 만드는 것에만 집중하면 유지보수나 확장성을 고려하지 못해 예상치 못한 문제가 발생할 수 있기 때문입니다. 그렇기에 저는 새로운 기술을 배울 때도 단순히 사용법을 익히는 것이 아니라, “왜 이 기술이 필요한가?”, “기존 방식과 비교했을 때 어떤 차이가 있는가?”를 고려하여 개발에 적용하려 합니다.\n이러한 원칙을 바탕으로 관련 자격증, 책, 인터넷 강의, 소스 코드 분석 등을 통해 다양한 상황과 그에 맞는 기술들에 대해 공부를 하고 있으며, 이렇게 얻게 된 지식과 경험으로 서비스의 안정성과 확장성을 고려한 개발을 하고 있습니다.\n\n마치며…\n이제는 다양한 금융 서비스 개발을 바탕으로 새로운 기회를 찾고 있습니다.  \n함께 일하고 싶다면 아래의 연락처로 연락바랍니다!  \n\n  \n   Email\n  \n   GitHub\n"}}